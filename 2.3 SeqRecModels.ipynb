{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 序列推荐模型\n",
    "# GRU4Rec、Caser（基于CNN）、DIN、DIEN\n",
    "# 基于transformer: SASRec、BSTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dba20d208aba82",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T08:53:09.674705300Z",
     "start_time": "2023-09-04T08:53:07.551786500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446 1548\n",
      "(446, 81)\n",
      "[[ 397  303  260  306  312  744  257  285  338  270  682  862  328 1543\n",
      "   344  881  326  298  867  265  673 1491  301  337  353  261  300 1260\n",
      "  1238  302  325  334  331  351  347 1090  683  901  897  272  345   49\n",
      "   585  309  521  126  386 1282 1038  539  288  417  418  931 1444  804\n",
      "   164  933  941 1326  686 1001  316  324 1128  900 1091 1349  710  716\n",
      "   470 1499  225   98 1508  357  365  757  887  248  633]\n",
      " [ 344  773  365  397  445   48  374   62  431  981  231  780  384  109\n",
      "    39  775 1021  929 1022  393   93  399   89  386  569  715   66 1059\n",
      "   748  414  459  418  139  832  495  831 1413  413  398  396   77  784\n",
      "   717  786   50  142  768  259 1159  394   11  917  793 1306 1307  810\n",
      "   302  944 1328  564   53  293  141  212  778  645  825  839  328  332\n",
      "  1234 1363  342 1247  485  107 1134 1137  369 1277  254]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# 加载数据集2成序列数据集，评分[0,1,2]为负反馈，评分[3,4,5]为正反馈，只保留正样本，构造简单序列推荐数据集\n",
    "# 数据集：ml-100k\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(100)\n",
    "\n",
    "# 加载数据: >=3分为正，用户评分次数不低于50，只保留最后50个，拆分为40: 5 + 15负例 (随机采样): 5 + 15负例 (随机采样)\n",
    "ratings = np.array([[int(x) for x in line.strip().split('\\t')[:4]] for line in open('./data/ml-100k/ua.base','r').read().strip().split('\\n')], dtype=np.int32)\n",
    "ratings_pd = pd.DataFrame({feature_name: list(feature_data) for feature_name, feature_data in zip(['user_id','item_id','rating','timestamp'], ratings.T)})\n",
    "pos_ratings_pd = ratings_pd[ratings_pd['rating']>2.9][['user_id','item_id','timestamp']].dropna().sort_values('timestamp') # 已经排序了\n",
    "pos_ratings_pd = pos_ratings_pd.groupby('user_id').filter(lambda x: x['user_id'].count()>=50)\n",
    "userid2id = {user_id: i for i, user_id in enumerate(sorted(list(set(pos_ratings_pd['user_id'].tolist()))))}\n",
    "itemid2id = {item_id: i for i, item_id in enumerate(sorted(list(set(pos_ratings_pd['item_id'].tolist()))))}\n",
    "print(len(userid2id), len(itemid2id))\n",
    "del ratings, ratings_pd\n",
    "\n",
    "# new id\n",
    "user_train_validate_test = {}\n",
    "for user,item,t in pos_ratings_pd.values:\n",
    "    u, i = userid2id[user], itemid2id[item]\n",
    "    if u not in user_train_validate_test:\n",
    "        user_train_validate_test[u] = [i]\n",
    "    else:\n",
    "        user_train_validate_test[u].append(i)\n",
    "    user_train_validate_test[u] = user_train_validate_test[u][-50:]\n",
    "train_seq_len = 40\n",
    "pos_num = 5\n",
    "neg_sample_num = 15\n",
    "def sample(low, high, notinset, num):\n",
    "    nums = set([])\n",
    "    n = num\n",
    "    while n>0:\n",
    "        id = random.randint(low, high)\n",
    "        if id not in notinset and id not in nums:\n",
    "            nums.add(id)\n",
    "            n -= 1\n",
    "    return list(nums)\n",
    "data = np.zeros((len(user_train_validate_test), 81), dtype=np.int32)\n",
    "i = 0\n",
    "for user, train_validate_test in user_train_validate_test.items():\n",
    "    train, validate, test = train_validate_test[:train_seq_len], train_validate_test[-pos_num*2:-pos_num], train_validate_test[-pos_num:]\n",
    "    data[i, 0] = user\n",
    "    data[i,1:train_seq_len+1] = np.array(train)\n",
    "    samples = sample(0, len(itemid2id)-1, set(train_validate_test), neg_sample_num * 2)\n",
    "    data[i,1+train_seq_len : 1+train_seq_len+pos_num+neg_sample_num] = np.array(validate + samples[:neg_sample_num])\n",
    "    data[i,1+train_seq_len+pos_num+neg_sample_num : ] = np.array(test + samples[neg_sample_num:])\n",
    "    i += 1\n",
    "del user_train_validate_test\n",
    "print(data.shape)\n",
    "print(data[:2,:])\n",
    "\n",
    "# 继续加载info特征信息，内容特征\n",
    "occupation_dict = {'administrator':0, 'artist':1, 'doctor':2, 'educator':3, 'engineer':4, 'entertainment':5, 'executive':6, 'healthcare':7, 'homemaker':8, 'lawyer':9, 'librarian':10, 'marketing':11, 'none':12, 'other':13, 'programmer':14, 'retired':15, 'salesman':16, 'scientist':17, 'student':18, 'technician':19, 'writer':20}\n",
    "gender_dict={'M':1,'F':0}\n",
    "user_info = {}\n",
    "for line in open('./data/ml-100k/u.user','r', encoding='utf-8').read().strip().split('\\n'):\n",
    "    phs = line.strip().split('|')\n",
    "    if int(phs[0]) not in userid2id:\n",
    "        continue\n",
    "    uid = userid2id[int(phs[0])]\n",
    "    user_info[uid] = [gender_dict[phs[2]], occupation_dict[phs[3]]] # int(phs[1]) 为了方便，不要连续型特征\n",
    "user_num_features = 2\n",
    "item_info = {}\n",
    "for line in open('./data/ml-100k/u.item','r', encoding='ISO-8859-1').read().strip().split('\\n'):\n",
    "    phs = line.strip().split('|')\n",
    "    if int(phs[0]) not in itemid2id:\n",
    "        continue\n",
    "    iid = itemid2id[int(phs[0])]\n",
    "    item_info[iid] = phs[5:]\n",
    "item_num_features = 19\n",
    "num_users = len(user_info)\n",
    "num_items = len(item_info)\n",
    "num_features = 21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "133c7cc9f9ed46e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:22:48.694168200Z",
     "start_time": "2023-09-01T08:22:13.104247100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-01 16:22:16] epoch=[1/10], train_ce_loss: 0.7405, train_ndcg: 0.6901, validate_ce_loss: 0.7556, validate_ndcg: 0.6248\n",
      "[2023-09-01 16:22:20] epoch=[2/10], train_ce_loss: 0.6774, train_ndcg: 0.8633, validate_ce_loss: 0.7632, validate_ndcg: 0.6208\n",
      "[2023-09-01 16:22:23] epoch=[3/10], train_ce_loss: 0.6616, train_ndcg: 0.8945, validate_ce_loss: 0.7653, validate_ndcg: 0.6203\n",
      "[2023-09-01 16:22:27] epoch=[4/10], train_ce_loss: 0.6592, train_ndcg: 0.9063, validate_ce_loss: 0.7659, validate_ndcg: 0.6252\n",
      "[2023-09-01 16:22:30] epoch=[5/10], train_ce_loss: 0.6581, train_ndcg: 0.9107, validate_ce_loss: 0.7662, validate_ndcg: 0.6275\n",
      "[2023-09-01 16:22:34] epoch=[6/10], train_ce_loss: 0.6568, train_ndcg: 0.9145, validate_ce_loss: 0.7664, validate_ndcg: 0.6273\n",
      "[2023-09-01 16:22:38] epoch=[7/10], train_ce_loss: 0.6549, train_ndcg: 0.9156, validate_ce_loss: 0.7665, validate_ndcg: 0.6279\n",
      "[2023-09-01 16:22:41] epoch=[8/10], train_ce_loss: 0.6524, train_ndcg: 0.9182, validate_ce_loss: 0.7673, validate_ndcg: 0.6283\n",
      "[2023-09-01 16:22:45] epoch=[9/10], train_ce_loss: 0.6491, train_ndcg: 0.9213, validate_ce_loss: 0.7681, validate_ndcg: 0.6258\n",
      "[2023-09-01 16:22:48] epoch=[10/10], train_ce_loss: 0.6453, train_ndcg: 0.9226, validate_ce_loss: 0.7690, validate_ndcg: 0.6240\n"
     ]
    }
   ],
   "source": [
    "# GRU4Rec: 只用行为特征\n",
    "# user_embedding = GRU(item_embedding_seq)\n",
    "# y = user_embedding * item_embedding.T\n",
    "# 数据集：ml-100k\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=100\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len]).long(), torch.from_numpy(data[:,1+ train_seq_len:-(pos_num+neg_sample_num)]).long()), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len + pos_num]).long(), torch.from_numpy(data[:,-(pos_num+neg_sample_num) : ]).long()), batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, gru_num_layers=1):\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim, self.gru_num_layers = embedding_dim, gru_num_layers\n",
    "        self.item_embeddings = nn.Embedding(num_items, self.embedding_dim, padding_idx=-1)\n",
    "        torch.nn.init.kaiming_normal_(self.item_embeddings.weight.data)\n",
    "        self.gru = nn.GRU(input_size=self.embedding_dim, hidden_size=self.embedding_dim, num_layers=self.gru_num_layers, batch_first=True)\n",
    "    # [batch, seq_len], [batch, label_len]\n",
    "    def forward(self, item_seqs: torch.Tensor, test: torch.Tensor):\n",
    "        batch_len = item_seqs.shape[0]\n",
    "        # [batch, seq_len, dim]\n",
    "        item_seqs_embeddings = self.item_embeddings(item_seqs)\n",
    "        # [batch, label_len, dim]\n",
    "        test_embeddings = self.item_embeddings(test)\n",
    "        # gru输出最后的隐层输出当为user embedding\n",
    "        _, user_emb = self.gru(item_seqs_embeddings)\n",
    "        # [batch, dim * gru_num_layers]\n",
    "        user_emb = user_emb.reshape((batch_len, self.gru_num_layers * self.embedding_dim))\n",
    "        # predict\n",
    "        scores = torch.sigmoid(torch.bmm(test_embeddings.repeat([1,1,self.gru_num_layers]), user_emb.unsqueeze(-1)).squeeze())\n",
    "        return scores\n",
    "model = GRU4Rec(num_items = len(itemid2id), embedding_dim = dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-04 11:08:01] epoch=[1/10], train_ce_loss: 0.7375, train_ndcg: 0.6850, validate_ce_loss: 0.7630, validate_ndcg: 0.6297\n",
      "[2023-09-04 11:08:02] epoch=[2/10], train_ce_loss: 0.6722, train_ndcg: 0.8702, validate_ce_loss: 0.7703, validate_ndcg: 0.6816\n",
      "[2023-09-04 11:08:04] epoch=[3/10], train_ce_loss: 0.6641, train_ndcg: 0.8949, validate_ce_loss: 0.7714, validate_ndcg: 0.6793\n",
      "[2023-09-04 11:08:07] epoch=[4/10], train_ce_loss: 0.6638, train_ndcg: 0.8901, validate_ce_loss: 0.7710, validate_ndcg: 0.6796\n",
      "[2023-09-04 11:08:09] epoch=[5/10], train_ce_loss: 0.6635, train_ndcg: 0.8845, validate_ce_loss: 0.7705, validate_ndcg: 0.6776\n",
      "[2023-09-04 11:08:12] epoch=[6/10], train_ce_loss: 0.6636, train_ndcg: 0.8813, validate_ce_loss: 0.7709, validate_ndcg: 0.6782\n",
      "[2023-09-04 11:08:14] epoch=[7/10], train_ce_loss: 0.6636, train_ndcg: 0.8810, validate_ce_loss: 0.7698, validate_ndcg: 0.6809\n",
      "[2023-09-04 11:08:16] epoch=[8/10], train_ce_loss: 0.6636, train_ndcg: 0.8809, validate_ce_loss: 0.7700, validate_ndcg: 0.6805\n",
      "[2023-09-04 11:08:18] epoch=[9/10], train_ce_loss: 0.6636, train_ndcg: 0.8812, validate_ce_loss: 0.7698, validate_ndcg: 0.6812\n",
      "[2023-09-04 11:08:20] epoch=[10/10], train_ce_loss: 0.6637, train_ndcg: 0.8817, validate_ce_loss: 0.7709, validate_ndcg: 0.6807\n"
     ]
    }
   ],
   "source": [
    "#  Caser： \n",
    "#  y = dnn（用户行为序列的水平卷积 + 垂直卷积)\n",
    "# Convolutional Sequence Embedding Recommendation Model (Caser)\n",
    "# 数据集：ml-100k\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=100\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,: 1+ train_seq_len]).long(), torch.from_numpy(data[:,1+ train_seq_len:-(pos_num+neg_sample_num)]).long()), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,: 1+ train_seq_len]).long(), torch.from_numpy(data[:,-(pos_num+neg_sample_num) : ]).long()), batch_size=batch_size, shuffle=False, pin_memory=True) # 这里图方便\n",
    "\n",
    "class Caser(nn.Module):\n",
    "    def __init__(self, num_users, num_items, seq_len, v_out_chinnel, h_out_chinnel, embedding_dim, mpl_conv_layers=[16], final_mlp_layers=[32]):\n",
    "        super(Caser, self).__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.seq_len, self.v_out_chinnel, self.h_out_chinnel = seq_len, v_out_chinnel, h_out_chinnel\n",
    "        self.embedding_dim, self.mpl_conv_layers = embedding_dim, mpl_conv_layers\n",
    "        self.user_embeddings = nn.Embedding(num_users, self.embedding_dim, padding_idx=-1)\n",
    "        torch.nn.init.kaiming_normal_(self.user_embeddings.weight.data)\n",
    "        self.item_embeddings = nn.Embedding(num_items, self.embedding_dim, padding_idx=-1)\n",
    "        torch.nn.init.kaiming_normal_(self.item_embeddings.weight.data)\n",
    "        # 卷积部分\n",
    "        # L * d\n",
    "        # vertical conv layer：垂直卷积\n",
    "        self.conv_v = nn.Conv2d(1, v_out_chinnel, (seq_len,1)) # v_kernel (L*1)\n",
    "        self.conv_v_out_dim = v_out_chinnel * embedding_dim\n",
    "        # horizontal conv layer：水平卷积 (h变化的, d)\n",
    "        self.conv_h = nn.ModuleList([nn.Conv2d(1, h_out_chinnel, (i+1, embedding_dim)) for i in range(seq_len)]) # 还需要max pool在embedding_dim\n",
    "        self.conv_h_out_dim = h_out_chinnel * seq_len\n",
    "        # mlp部分\n",
    "        self.mpl_conv = nn.Sequential(nn.Linear(self.conv_v_out_dim + self.conv_h_out_dim, mpl_conv_layers[0]), nn.ReLU())\n",
    "        if len(mpl_conv_layers)>1:\n",
    "            for i, layer_dim in enumerate(mpl_conv_layers[1:]):\n",
    "                self.attention_net.append(nn.Linear(mpl_conv_layers[i], layer_dim))\n",
    "                self.attention_net.append(nn.ReLU())\n",
    "        # final mlp\n",
    "        self.final_mlp = nn.Sequential(nn.Linear(mpl_conv_layers[-1] + embedding_dim, final_mlp_layers[0]), nn.ReLU())\n",
    "        if len(final_mlp_layers)>1:\n",
    "            for i, layer_dim in enumerate(final_mlp_layers[1:]):\n",
    "                self.attention_net.append(nn.Linear(final_mlp_layers[i], layer_dim))\n",
    "                self.attention_net.append(nn.ReLU())\n",
    "        self.final_mlp.append(nn.Linear(final_mlp_layers[-1], embedding_dim))\n",
    "    def forward(self, users_item_seqs: torch.Tensor, test: torch.Tensor):\n",
    "        batch_len = users_item_seqs.shape[0]\n",
    "        user_emb = self.user_embeddings(users_item_seqs[:,0])\n",
    "        # [batch, seq_len, dim]\n",
    "        item_seqs_embeddings = self.item_embeddings(users_item_seqs[:,1:])\n",
    "        # [batch, label_len, dim]\n",
    "        test_embeddings = self.item_embeddings(test)\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        out, out_h, out_v = None, None, None\n",
    "        # vertical conv layer\n",
    "        out_v = self.conv_v(item_seqs_embeddings.unsqueeze(1)).squeeze()\n",
    "        out_v = out_v.reshape((batch_len, -1))\n",
    "        # horizontal conv layer\n",
    "        out_hs = []\n",
    "        for conv in self.conv_h:\n",
    "            conv_out = conv(item_seqs_embeddings.unsqueeze(1)).squeeze(-1)\n",
    "            pool_out = torch.max_pool1d(conv_out, conv_out.size(2)).squeeze(-1)\n",
    "            out_hs.append(pool_out)\n",
    "        out_h = torch.cat(out_hs, dim=1)\n",
    "        out = torch.cat([out_v, out_h], dim=1)\n",
    "        # fully-connected layer\n",
    "        z = self.mpl_conv(out)\n",
    "        x = torch.cat([z, user_emb], 1) #z is combined by seq item embs and user emb\n",
    "        t = self.final_mlp(x)\n",
    "        # final\n",
    "        seq_len = test_embeddings.shape[1]\n",
    "        y = torch.sigmoid(torch.sum(t.unsqueeze(1).repeat((1,seq_len,1)) * test_embeddings, dim=-1)).squeeze()\n",
    "        return y\n",
    "model = Caser(num_users=num_users, num_items=num_items, seq_len=train_seq_len, v_out_chinnel=4, h_out_chinnel=16, embedding_dim=dim, mpl_conv_layers=[16], final_mlp_layers=[32]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:08:20.677061100Z",
     "start_time": "2023-09-04T03:07:55.030283600Z"
    }
   },
   "id": "29c0a47a87673a49"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-03 00:17:34] epoch=[1/10], train_ce_loss: 0.7470, train_ndcg: 0.6494, validate_ce_loss: 0.7428, validate_ndcg: 0.6644\n",
      "[2023-09-03 00:17:35] epoch=[2/10], train_ce_loss: 0.7412, train_ndcg: 0.6671, validate_ce_loss: 0.7403, validate_ndcg: 0.6676\n",
      "[2023-09-03 00:17:37] epoch=[3/10], train_ce_loss: 0.7392, train_ndcg: 0.6733, validate_ce_loss: 0.7438, validate_ndcg: 0.6666\n",
      "[2023-09-03 00:17:38] epoch=[4/10], train_ce_loss: 0.7381, train_ndcg: 0.6805, validate_ce_loss: 0.7396, validate_ndcg: 0.6584\n",
      "[2023-09-03 00:17:39] epoch=[5/10], train_ce_loss: 0.7376, train_ndcg: 0.6855, validate_ce_loss: 0.7445, validate_ndcg: 0.6578\n",
      "[2023-09-03 00:17:41] epoch=[6/10], train_ce_loss: 0.7383, train_ndcg: 0.6833, validate_ce_loss: 0.7428, validate_ndcg: 0.6577\n",
      "[2023-09-03 00:17:42] epoch=[7/10], train_ce_loss: 0.7385, train_ndcg: 0.6853, validate_ce_loss: 0.7452, validate_ndcg: 0.6579\n",
      "[2023-09-03 00:17:43] epoch=[8/10], train_ce_loss: 0.7397, train_ndcg: 0.6860, validate_ce_loss: 0.7408, validate_ndcg: 0.6587\n",
      "[2023-09-03 00:17:45] epoch=[9/10], train_ce_loss: 0.7365, train_ndcg: 0.6856, validate_ce_loss: 0.7390, validate_ndcg: 0.6605\n",
      "[2023-09-03 00:17:46] epoch=[10/10], train_ce_loss: 0.7364, train_ndcg: 0.6853, validate_ce_loss: 0.7415, validate_ndcg: 0.6626\n"
     ]
    }
   ],
   "source": [
    "# DIN： Deep Interest Network\n",
    "# 阿里妈妈：使用内容特征和基于内容特征之上的行为序列。\n",
    "# y = dnn(user内容特征+行为item序列特征（attention sum）+candidate item内容特征)\n",
    "# 我这里实现没有用物品id的行为嵌入，所以效果不一定好。\n",
    "# 数据集：ml-100k，这里没有考虑连续型特征，故特征总数为2+19\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=50\n",
    "\n",
    "\n",
    "user_feature_vals = {}\n",
    "for i in range(user_num_features):\n",
    "    user_feature_vals[i] = sorted(list(set([val[i] for val in user_info.values()])))\n",
    "    for user, info in user_info.items():\n",
    "        user_info[user][i] = user_feature_vals[i].index(info[i])\n",
    "item_feature_vals = {}\n",
    "for i in range(item_num_features):\n",
    "    item_feature_vals[i] = sorted(list(set([val[i] for val in item_info.values()])))\n",
    "    for item, info in item_info.items():\n",
    "        item_info[item][i] = item_feature_vals[i].index(info[i])\n",
    "\n",
    "user_profile_data = np.array([user_info[u] for u in data[:,0]]) # [data_len, ufeature]\n",
    "item_seq_profile_data = np.array([[item_info[item] for item in item_seq] for item_seq in data[:,1:]]) # [data_len, seq_len, ufeature]\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(item_seq_profile_data[:,:train_seq_len,:]).long(),\n",
    "                                                torch.from_numpy(item_seq_profile_data[:,train_seq_len:(train_seq_len + pos_num + neg_sample_num),:]).long()\n",
    "                                                ), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(item_seq_profile_data[:,:train_seq_len + pos_num,:]).long(),\n",
    "                                                torch.from_numpy(item_seq_profile_data[:,-(pos_num + neg_sample_num):,:]).long()\n",
    "                                               ), batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, user_profile_feature: [tuple], item_profile_feature: [tuple], profile_feature_embedding_dim: int, \n",
    "                 dnn_layer_dims: list[int], attention_layer_dims: list[int]):\n",
    "        super(DIN, self).__init__()\n",
    "        # 内容特征\n",
    "        self.user_profile_feature, self.item_profile_feature, self.profile_feature_embedding_dim = user_profile_feature, item_profile_feature, profile_feature_embedding_dim\n",
    "        self.user_profile_embed = nn.ModuleDict({'user_embed_' + str(i): nn.Embedding(num_embeddings=valcount, embedding_dim=profile_feature_embedding_dim) for i, valcount in user_profile_feature})\n",
    "        self.item_profile_embed = nn.ModuleDict({'item_embed_' + str(i): nn.Embedding(num_embeddings=valcount, embedding_dim=profile_feature_embedding_dim) for i, valcount in item_profile_feature})\n",
    "        self.user_profile_all_embed_dim = profile_feature_embedding_dim * len(user_profile_feature)\n",
    "        self.item_profile_all_embed_dim = profile_feature_embedding_dim * len(item_profile_feature)\n",
    "        # 注意力 attention net：基于行为特征\n",
    "        self.dnn_layer_dims, self.attention_layer_dims = dnn_layer_dims, attention_layer_dims\n",
    "        self.attention_input_dim = len(user_profile_feature) * profile_feature_embedding_dim + len(item_profile_feature) * profile_feature_embedding_dim + len(user_profile_feature) * len(item_profile_feature)\n",
    "        self.attention_net = nn.Sequential(nn.Linear(self.attention_input_dim, attention_layer_dims[0]))\n",
    "        if len(attention_layer_dims)>1:\n",
    "            for i, layer_dim in enumerate(attention_layer_dims[1:]):\n",
    "                self.attention_net.append(nn.Linear(attention_layer_dims[i], layer_dim))\n",
    "                self.attention_net.append(nn.ReLU())\n",
    "        self.attention_net.append(nn.Linear(attention_layer_dims[-1], 1))\n",
    "        self.attention_net.append(nn.Softmax(dim=-2))\n",
    "        # final dnn\n",
    "        self.all_embedding_dim = len(self.item_profile_feature) * self.profile_feature_embedding_dim * 2\n",
    "        self.final_dnn_network = nn.Sequential(nn.Linear(self.all_embedding_dim, dnn_layer_dims[0]), nn.ReLU())\n",
    "        if len(dnn_layer_dims) > 1:\n",
    "            for i, layer_dim in enumerate(dnn_layer_dims[1:]):\n",
    "                self.final_dnn_network.append(nn.Linear(dnn_layer_dims[i], layer_dim))\n",
    "                self.final_dnn_network.append(nn.ReLU())\n",
    "        self.final_dnn_network.append(nn.Linear(dnn_layer_dims[-1], 1))\n",
    "        self.final_dnn_network.append(nn.Sigmoid())\n",
    "    # torch.Tensor([batch, feature]),   torch.Tensor([batch, seq_len, feature]),   torch.Tensor([batch, seq_len, feature])\n",
    "    def forward(self, user_profiles, item_history_list_profile, item_future_list_profile):\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        # user profile: [batch, feature * embed_dim]\n",
    "        user_profile_embeddings = torch.cat([self.user_profile_embed['user_embed_' + str(i)](user_profiles[:,i].long()) for i in range(user_profiles.shape[-1])], axis=-1)\n",
    "        user_profile_embeddings = user_profile_embeddings.reshape((batch_len, len(self.user_profile_feature), self.profile_feature_embedding_dim)) # [batch, feature, embed_dim]\n",
    "        # item_history_list_profile: torch.Tensor([batch, seq_len, feature * embed_dim])\n",
    "        seq_len = item_history_list_profile.shape[1]\n",
    "        item_history_list_profile_embeddings = torch.cat([self.item_profile_embed['item_embed_' + str(i)](item_history_list_profile[:,:,i].long()) for i in range(item_history_list_profile.shape[-1])], axis=-1)\n",
    "        item_history_list_profile_embeddings = item_history_list_profile_embeddings.reshape((batch_len, seq_len, len(self.item_profile_feature), self.profile_feature_embedding_dim)) # [batch, seq_len, feature, embed_dim]\n",
    "        # # attention\n",
    "        a = user_profile_embeddings.unsqueeze(1).repeat((1,seq_len,1,1)).reshape((batch_len * seq_len, len(self.user_profile_feature), self.profile_feature_embedding_dim))\n",
    "        b = item_history_list_profile_embeddings.reshape((batch_len * seq_len, len(self.item_profile_feature), self.profile_feature_embedding_dim))\n",
    "        ab = torch.bmm(a, b.permute(0,2,1)).reshape((batch_len, seq_len, len(self.user_profile_feature) * len(self.item_profile_feature)))\n",
    "        a_ = a.reshape((batch_len, seq_len, len(self.user_profile_feature) * self.profile_feature_embedding_dim))\n",
    "        b_ = b.reshape((batch_len, seq_len, len(self.item_profile_feature) * self.profile_feature_embedding_dim))\n",
    "        # print(a_.shape, b_.shape, ab.shape) # torch.Size([100, 40, 100]) torch.Size([100, 40, 950]) torch.Size([100, 40, 38])\n",
    "        in_attention = torch.cat([a_, b_, ab], dim=-1) # [batch, seq_len, feature, 3 * embed_dim]\n",
    "        # [batch, seq_len, 1] * [batch, seq_len, feature * embed_dim]\n",
    "        out_attention = torch.sum(self.attention_net(in_attention) * item_history_list_profile_embeddings.reshape((batch_len, seq_len, -1)), dim=1) # [batch, feature * embed_dim]\n",
    "\n",
    "        # # 以上处理user profile和行为历史，下面进行与candidate组合预测， item_future_list 和 item_future_list_profile\n",
    "        seq_len_ = item_future_list_profile.shape[1]\n",
    "        item_future_list_profile_embeddings = torch.cat([self.item_profile_embed['item_embed_' + str(i)](item_future_list_profile[:,:,i].long()) for i in range(item_future_list_profile.shape[-1])], axis=-1)\n",
    "        # print(item_future_list_profile_embeddings.shape, batch_len, seq_len_, len(self.item_profile_feature) * self.profile_feature_embedding_dim) # torch.Size([100, 20, 950]) 100 20 950\n",
    "        item_future_list_profile_embeddings = item_future_list_profile_embeddings.reshape((batch_len, seq_len_, len(self.item_profile_feature) * self.profile_feature_embedding_dim)) # [batch, seq_len, feature * embed_dim]\n",
    "        \n",
    "        x = torch.cat([out_attention.unsqueeze(1).repeat((1,seq_len_,1)), item_future_list_profile_embeddings], dim=-1)\n",
    "        output = self.final_dnn_network(x).squeeze()\n",
    "        return output\n",
    "model = DIN(user_profile_feature = [(i,len(list_)) for i, list_ in user_feature_vals.items()], item_profile_feature= [(i,len(list_)) for i, list_ in item_feature_vals.items()], \n",
    "            profile_feature_embedding_dim = dim, dnn_layer_dims = [16], attention_layer_dims=[16]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        user_profiles, item_history_list_profile, item_future_list_profile = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        # print(item_history_list_profile.shape, item_future_list_profile.shape)\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list_profile = item_history_list_profile.to(device)\n",
    "        item_future_list_profile = item_future_list_profile.to(device)\n",
    "        output = model(user_profiles, item_history_list_profile, item_future_list_profile)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        user_profiles, item_history_list_profile, item_future_list_profile = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list_profile = item_history_list_profile.to(device)\n",
    "        item_future_list_profile = item_future_list_profile.to(device)\n",
    "        output = model(user_profiles, item_history_list_profile, item_future_list_profile)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n",
    "     \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-02T15:47:43.354772Z"
    }
   },
   "id": "ae55ee82dfec0944"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-03 11:26:10] epoch=[1/10], train_ce_loss: 0.7461, train_ndcg: 0.6509, validate_ce_loss: 0.7435, validate_ndcg: 0.6702\n",
      "[2023-09-03 11:26:22] epoch=[2/10], train_ce_loss: 0.7398, train_ndcg: 0.6730, validate_ce_loss: 0.7416, validate_ndcg: 0.6630\n",
      "[2023-09-03 11:26:34] epoch=[3/10], train_ce_loss: 0.7386, train_ndcg: 0.6827, validate_ce_loss: 0.7431, validate_ndcg: 0.6596\n",
      "[2023-09-03 11:26:47] epoch=[4/10], train_ce_loss: 0.7376, train_ndcg: 0.6872, validate_ce_loss: 0.7421, validate_ndcg: 0.6648\n",
      "[2023-09-03 11:26:59] epoch=[5/10], train_ce_loss: 0.7366, train_ndcg: 0.6832, validate_ce_loss: 0.7396, validate_ndcg: 0.6614\n",
      "[2023-09-03 11:27:11] epoch=[6/10], train_ce_loss: 0.7362, train_ndcg: 0.6826, validate_ce_loss: 0.7400, validate_ndcg: 0.6607\n",
      "[2023-09-03 11:27:23] epoch=[7/10], train_ce_loss: 0.7358, train_ndcg: 0.6808, validate_ce_loss: 0.7422, validate_ndcg: 0.6628\n",
      "[2023-09-03 11:27:35] epoch=[8/10], train_ce_loss: 0.7353, train_ndcg: 0.6830, validate_ce_loss: 0.7397, validate_ndcg: 0.6604\n",
      "[2023-09-03 11:27:47] epoch=[9/10], train_ce_loss: 0.7361, train_ndcg: 0.6834, validate_ce_loss: 0.7400, validate_ndcg: 0.6614\n",
      "[2023-09-03 11:27:59] epoch=[10/10], train_ce_loss: 0.7358, train_ndcg: 0.6822, validate_ce_loss: 0.7421, validate_ndcg: 0.6634\n"
     ]
    }
   ],
   "source": [
    "# DIEN\n",
    "# Deep Interest Evolution Network for Click-Through Rate Prediction, 2018\n",
    "# y = dnn(采用AUGRU来建模行为序列，融合内容特征)\n",
    "# 简单实现，适应这个数据集\n",
    "# 数据集：ml-100k\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=50\n",
    "\n",
    "user_feature_vals = {}\n",
    "for i in range(user_num_features):\n",
    "    user_feature_vals[i] = sorted(list(set([val[i] for val in user_info.values()])))\n",
    "    for user, info in user_info.items():\n",
    "        user_info[user][i] = user_feature_vals[i].index(info[i])\n",
    "item_feature_vals = {}\n",
    "for i in range(item_num_features):\n",
    "    item_feature_vals[i] = sorted(list(set([val[i] for val in item_info.values()])))\n",
    "    for item, info in item_info.items():\n",
    "        item_info[item][i] = item_feature_vals[i].index(info[i])\n",
    "\n",
    "user_profile_data = np.array([user_info[u] for u in data[:,0]]) # [data_len, ufeature]\n",
    "item_seq_profile_data = np.array([[item_info[item] for item in item_seq] for item_seq in data[:,1:]]) # [data_len, seq_len, ufeature]\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(item_seq_profile_data[:,:train_seq_len,:]).long(),\n",
    "                                                torch.from_numpy(item_seq_profile_data[:,train_seq_len:(train_seq_len + pos_num + neg_sample_num),:]).long()\n",
    "                                                ), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(item_seq_profile_data[:,:train_seq_len + pos_num,:]).long(),\n",
    "                                                torch.from_numpy(item_seq_profile_data[:,-(pos_num + neg_sample_num):,:]).long()\n",
    "                                               ), batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "class AUGRUCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AUGRUCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.linear_ih = nn.Linear(input_dim, 3 * hidden_dim).to(device)\n",
    "        self.linear_hh = nn.Linear(hidden_dim, 3 * hidden_dim).to(device)\n",
    "    # [batch, test_len, n_feature * dim], [batch, test_len, dim], [batch, test_len, dim]\n",
    "    def forward(self, inputs, hx, att_score):\n",
    "        gi = self.linear_ih(inputs)\n",
    "        gh = self.linear_hh(hx)\n",
    "        i_r, i_z, i_n = gi[:,:,:self.hidden_dim], gi[:,:,self.hidden_dim:-self.hidden_dim], gi[:,:,-self.hidden_dim:]\n",
    "        h_r, h_z, h_n = gh[:,:,:self.hidden_dim], gi[:,:,self.hidden_dim:-self.hidden_dim], gi[:,:,-self.hidden_dim:]\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        update_gate = torch.sigmoid(i_z + h_z)\n",
    "        new_state = torch.tanh(i_n + reset_gate * h_n)\n",
    "        update_gate = att_score * update_gate\n",
    "        hy = (1. - update_gate) * hx + update_gate * new_state\n",
    "        return hy\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.linear_hh.parameters()] + [para for para in self.linear_ih.parameters()]\n",
    "class AUGRU(nn.Module):\n",
    "    # n_feature * dim, \n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AUGRU, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_net = nn.Sequential(nn.Linear(input_dim*2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim), nn.Sigmoid())\n",
    "        self.agrucell = AUGRUCell(input_dim, hidden_dim).to(device)\n",
    "    # , [batch, seq_len, n_feature * dim], [batch, test_len, n_feature * dim]\n",
    "    # torch.Size([100, 40, 950]) torch.Size([100, 20, 950])\n",
    "    def forward(self, history, target):\n",
    "        batch_len, seq_len = history.shape[0], history.shape[1]\n",
    "        test_len = target.shape[1]\n",
    "        # # [batch, seq_len, test_len, n_feature * dim]  \n",
    "        history_ = history.unsqueeze(-2).repeat((1,1,test_len,1))\n",
    "        target_ = target.unsqueeze(1).repeat((1,seq_len,1,1))\n",
    "        # # [batch, seq_len, test_len, dim]\n",
    "        # torch.Size([100, 40, 20, 950]) torch.Size([100, 40, 20, 950]) 50\n",
    "        attention = self.attention_net(torch.cat([history_, target_], dim=-1))\n",
    "        h = torch.zeros((batch_len, test_len, self.hidden_dim)).to(device) # h0\n",
    "        for i in range(seq_len):\n",
    "            attention_ = attention[:,i,:,:] # [batch, test_len, 1]\n",
    "            # history_[:,i,:,:]: [batch, test_len, n_feature * dim]\n",
    "            # h [batch, test_len, dim]\n",
    "            h = self.agrucell(history_[:,i,:,:], h, attention_)\n",
    "        # [batch_len, test_len, hidden_dim]\n",
    "        return h\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.attention_net.parameters()] + [para for para in self.agrucell.parameters()]\n",
    "class DIEN(nn.Module):\n",
    "    def __init__(self, user_profile_feature: [tuple], item_profile_feature: [tuple], profile_feature_embedding_dim: int, hidden_dim: int,\n",
    "                 dnn_layer_dims: list[int]):\n",
    "        super(DIEN, self).__init__()\n",
    "        # 内容特征\n",
    "        self.user_profile_feature, self.item_profile_feature, self.profile_feature_embedding_dim = user_profile_feature, item_profile_feature, profile_feature_embedding_dim\n",
    "        self.user_profile_embed = nn.ModuleDict({'user_embed_' + str(i): nn.Embedding(num_embeddings=valcount, embedding_dim=profile_feature_embedding_dim) for i, valcount in user_profile_feature})\n",
    "        self.item_profile_embed = nn.ModuleDict({'item_embed_' + str(i): nn.Embedding(num_embeddings=valcount, embedding_dim=profile_feature_embedding_dim) for i, valcount in item_profile_feature})\n",
    "        self.user_profile_all_embed_dim = profile_feature_embedding_dim * len(user_profile_feature)\n",
    "        self.item_profile_all_embed_dim = profile_feature_embedding_dim * len(item_profile_feature)\n",
    "        self.dnn_layer_dims, self.hidden_dim = dnn_layer_dims, hidden_dim\n",
    "        # augru\n",
    "        self.augru = AUGRU(profile_feature_embedding_dim * len(item_profile_feature), hidden_dim)\n",
    "        # final dnn\n",
    "        self.all_embedding_dim = hidden_dim + profile_feature_embedding_dim * len(self.item_profile_feature) + profile_feature_embedding_dim * len(self.user_profile_feature)\n",
    "        self.final_dnn_network = nn.Sequential(nn.Linear(self.all_embedding_dim, dnn_layer_dims[0]), nn.ReLU())\n",
    "        if len(dnn_layer_dims) > 1:\n",
    "            for i, layer_dim in enumerate(dnn_layer_dims[1:]):\n",
    "                self.final_dnn_network.append(nn.Linear(dnn_layer_dims[i], layer_dim))\n",
    "                self.final_dnn_network.append(nn.ReLU())\n",
    "        self.final_dnn_network.append(nn.Linear(dnn_layer_dims[-1], 1))\n",
    "        self.final_dnn_network.append(nn.Sigmoid())\n",
    "    # torch.Tensor([batch, feature]),   torch.Tensor([batch, seq_len, feature]),   torch.Tensor([batch, seq_len, feature])\n",
    "    def forward(self, user_profiles, item_history_list_profile, item_future_list_profile):\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        # user profile: [batch, feature * embed_dim]\n",
    "        user_profile_embeddings = torch.cat([self.user_profile_embed['user_embed_' + str(i)](user_profiles[:,i].long()) for i in range(user_profiles.shape[-1])], axis=-1)\n",
    "        user_profile_embeddings = user_profile_embeddings.reshape((batch_len, len(self.user_profile_feature) * self.profile_feature_embedding_dim)) # [batch, feature, embed_dim]\n",
    "        # item_history_list_profile: torch.Tensor([batch, seq_len, feature * embed_dim])\n",
    "        seq_len = item_history_list_profile.shape[1]\n",
    "        item_history_list_profile_embeddings = torch.cat([self.item_profile_embed['item_embed_' + str(i)](item_history_list_profile[:,:,i].long()) for i in range(item_history_list_profile.shape[-1])], axis=-1)\n",
    "        item_history_list_profile_embeddings = item_history_list_profile_embeddings.reshape((batch_len, seq_len, len(self.item_profile_feature) * self.profile_feature_embedding_dim)) # [batch, seq_len, feature, embed_dim]\n",
    "        # 以上处理user profile和行为历史，下面进行与candidate组合预测， item_future_list 和 item_future_list_profile\n",
    "        seq_len_ = item_future_list_profile.shape[1]\n",
    "        item_future_list_profile_embeddings = torch.cat([self.item_profile_embed['item_embed_' + str(i)](item_future_list_profile[:,:,i].long()) for i in range(item_future_list_profile.shape[-1])], axis=-1)\n",
    "        item_future_list_profile_embeddings = item_future_list_profile_embeddings.reshape((batch_len, seq_len_, len(self.item_profile_feature) * self.profile_feature_embedding_dim)) # [batch, seq_len, feature * embed_dim]\n",
    "        # [batch_len, test_len, hidden_dim]\n",
    "        h = self.augru(item_history_list_profile_embeddings, item_future_list_profile_embeddings)\n",
    "        x = torch.cat([h, user_profile_embeddings.unsqueeze(1).repeat((1,seq_len_,1)), item_future_list_profile_embeddings], dim=-1)\n",
    "        output = self.final_dnn_network(x).squeeze() # [batch, seq_len, 1]\n",
    "        return output\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.user_profile_embed.parameters()] + [para for para in self.item_profile_embed.parameters()] + [para for para in self.augru.parameters()] + [para for para in self.final_dnn_network.parameters()]\n",
    "model = DIEN(user_profile_feature = [(i,len(list_)) for i, list_ in user_feature_vals.items()], item_profile_feature= [(i,len(list_)) for i, list_ in item_feature_vals.items()], hidden_dim=dim,\n",
    "            profile_feature_embedding_dim = dim, dnn_layer_dims = [16]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        user_profiles, item_history_list_profile, item_future_list_profile = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        # print(item_history_list_profile.shape, item_future_list_profile.shape)\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list_profile = item_history_list_profile.to(device)\n",
    "        item_future_list_profile = item_future_list_profile.to(device)\n",
    "        output = model(user_profiles, item_history_list_profile, item_future_list_profile)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        user_profiles, item_history_list_profile, item_future_list_profile = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list_profile = item_history_list_profile.to(device)\n",
    "        item_future_list_profile = item_future_list_profile.to(device)\n",
    "        output = model(user_profiles, item_history_list_profile, item_future_list_profile)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-03T03:25:56.842341Z"
    }
   },
   "id": "7ed56678fc0da646"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-04 15:20:24] epoch=[1/10], train_ce_loss: 0.7626, train_ndcg: 0.6294, validate_ce_loss: 0.7687, validate_ndcg: 0.6553\n",
      "[2023-09-04 15:20:31] epoch=[2/10], train_ce_loss: 0.7204, train_ndcg: 0.7175, validate_ce_loss: 0.7703, validate_ndcg: 0.6699\n",
      "[2023-09-04 15:20:35] epoch=[3/10], train_ce_loss: 0.7016, train_ndcg: 0.7747, validate_ce_loss: 0.7699, validate_ndcg: 0.6796\n",
      "[2023-09-04 15:20:38] epoch=[4/10], train_ce_loss: 0.6929, train_ndcg: 0.8143, validate_ce_loss: 0.7731, validate_ndcg: 0.6920\n",
      "[2023-09-04 15:20:42] epoch=[5/10], train_ce_loss: 0.6858, train_ndcg: 0.8337, validate_ce_loss: 0.7740, validate_ndcg: 0.6799\n",
      "[2023-09-04 15:20:45] epoch=[6/10], train_ce_loss: 0.6799, train_ndcg: 0.8392, validate_ce_loss: 0.7731, validate_ndcg: 0.6790\n",
      "[2023-09-04 15:20:48] epoch=[7/10], train_ce_loss: 0.6759, train_ndcg: 0.8419, validate_ce_loss: 0.7711, validate_ndcg: 0.6859\n",
      "[2023-09-04 15:20:51] epoch=[8/10], train_ce_loss: 0.6733, train_ndcg: 0.8422, validate_ce_loss: 0.7700, validate_ndcg: 0.6870\n",
      "[2023-09-04 15:20:54] epoch=[9/10], train_ce_loss: 0.6709, train_ndcg: 0.8392, validate_ce_loss: 0.7695, validate_ndcg: 0.6835\n",
      "[2023-09-04 15:20:57] epoch=[10/10], train_ce_loss: 0.6693, train_ndcg: 0.8365, validate_ce_loss: 0.7693, validate_ndcg: 0.6859\n"
     ]
    }
   ],
   "source": [
    "# SASRec：（效果很好，基于transformer，但模型本身创新意义不大）\n",
    "# Self-attentive Sequential Recommendation\n",
    "# 自回归transformer模型，casual attention，基本架构照抄transformer，next-step预测形式，拿最后的token输出采用mf计算最终得分。\n",
    "# 只用了行为item embedding，没有用内容特征\n",
    "# 数据集：ml-100k\n",
    "\n",
    "import math, copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=100\n",
    "num_attention_heads = 4 # dim % 4\n",
    "num_hidden_layers = 1\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len] + 1).long(), torch.from_numpy(data[:,1+ train_seq_len:-(pos_num+neg_sample_num)]+1).long()), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len] + 1).long(), torch.from_numpy(data[:,-(pos_num+neg_sample_num) : ] + 1).long()), batch_size=batch_size, shuffle=False, pin_memory=True) # 这里图方便\n",
    "num_items += 1 # 因为data中id为0表示mask，所以这里做了简便处理\n",
    "\n",
    "# 层内归一化的层（输入的特征维度归一化）\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [self.weight, self.bias]\n",
    "# 自注意力层\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        assert hidden_size % num_attention_heads == 0\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.attention_head_size = int(hidden_size / num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        # w_q, w_k, w_v\n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.attn_dropout = nn.Dropout(attention_probs_dropout_prob)\n",
    "        # 做完self-attention 做一个前馈全连接 LayerNorm 输出\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LayerNorm = LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.out_dropout = nn.Dropout(hidden_dropout_prob)\n",
    "    def _transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    def forward(self, input_tensor, attention_mask):\n",
    "        # q, k, v\n",
    "        mixed_query_layer = self.query(input_tensor)\n",
    "        mixed_key_layer = self.key(input_tensor)\n",
    "        mixed_value_layer = self.value(input_tensor)\n",
    "        query_layer = self._transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self._transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self._transpose_for_scores(mixed_value_layer)\n",
    "        # attention\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        attention_probs = self.attn_dropout(attention_probs)\n",
    "        # attention * v\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        # fnn + norm\n",
    "        hidden_states = self.out_dropout(self.dense(context_layer))\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.query.parameters()] + [para for para in self.key.parameters()] + [para for para in self.value.parameters()] + [para for para in self.dense.parameters()] + self.LayerNorm.parameters()\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_dropout_prob):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.conv1d_1 = nn.Conv1d(hidden_size, hidden_size, kernel_size=(1,))\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv1d_2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=(1,))\n",
    "        self.LayerNorm = LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "    def forward(self, input_tensor):\n",
    "        hidden_states = self.conv1d_1(input_tensor.transpose(1, 2))\n",
    "        hidden_states = hidden_states.transpose(1, 2)\n",
    "        hidden_states = self.activation(hidden_states)\n",
    "        hidden_states = self.conv1d_2(hidden_states.transpose(1, 2))\n",
    "        hidden_states = hidden_states.transpose(1, 2)\n",
    "        hidden_states = self.activation(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.conv1d_1.parameters()] + [para for para in self.conv1d_2.parameters()] + self.LayerNorm.parameters()\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, attention_probs_dropout_prob):\n",
    "        super(Layer, self).__init__()\n",
    "        self.attention = SelfAttention(hidden_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob)\n",
    "        self.intermediate = PointWiseFeedForward(hidden_size, hidden_dropout_prob)\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        return intermediate_output\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.attention.parameters()] + [para for para in self.intermediate.parameters()]\n",
    "class SASEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, attention_probs_dropout_prob, num_hidden_layers=1):\n",
    "        super(SASEncoder, self).__init__()\n",
    "        layer = Layer(hidden_size, num_attention_heads, hidden_dropout_prob, attention_probs_dropout_prob)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(num_hidden_layers)])\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:\n",
    "            return hidden_states\n",
    "        return all_encoder_layers\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        paras = []\n",
    "        for layer in self.layer:\n",
    "            for para in layer.parameters():\n",
    "                paras.append(para)\n",
    "        return paras\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, seq_len, num_attention_heads, num_hidden_layers=1, hidden_dropout_prob=0., attention_probs_dropout_prob=0.):\n",
    "        super(SASRec, self).__init__()\n",
    "        self.num_items, self.embedding_dim, self.seq_len = num_items, embedding_dim, seq_len\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(seq_len, embedding_dim)\n",
    "        self.item_encoder = SASEncoder(embedding_dim, num_attention_heads, hidden_dropout_prob, attention_probs_dropout_prob, num_hidden_layers)\n",
    "        self.LayerNorm = LayerNorm(embedding_dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "    def _add_position_embedding(self, sequence: torch.Tensor) -> torch.Tensor:\n",
    "        seq_length = sequence.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=sequence.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(sequence)\n",
    "        item_embeddings = self.item_embeddings(sequence)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        sequence_emb = item_embeddings + position_embeddings\n",
    "        sequence_emb = self.LayerNorm(sequence_emb)\n",
    "        sequence_emb = self.dropout(sequence_emb)\n",
    "        return sequence_emb\n",
    "    def _get_embedding_and_mask(self, input_ids):\n",
    "        sequence_emb = self._add_position_embedding(input_ids)\n",
    "        attention_mask = (input_ids > 0).long()\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # torch.int64\n",
    "        max_len = attention_mask.size(-1)\n",
    "        attn_shape = (1, max_len, max_len)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1)  # torch.uint8\n",
    "        subsequent_mask = (subsequent_mask == 0).unsqueeze(1)\n",
    "        subsequent_mask = subsequent_mask.long()\n",
    "        subsequent_mask = subsequent_mask.to(device)\n",
    "        extended_attention_mask = extended_attention_mask * subsequent_mask\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        return sequence_emb, extended_attention_mask\n",
    "    def get_seq_out(self, input_ids):\n",
    "        sequence_emb, extended_attention_mask = self._get_embedding_and_mask(input_ids)\n",
    "        sequence_output = self.item_encoder(sequence_emb, extended_attention_mask, output_all_encoded_layers=False)\n",
    "        return sequence_output\n",
    "    def forward(self, input_ids, test):\n",
    "        batch_len, seq_len = test.shape[0], test.shape[1]\n",
    "        sequence_output = self.get_seq_out(input_ids)\n",
    "        test_embeddings = self.item_embeddings(test)\n",
    "        # mf: 原论文中采用mf，这里拿最后一个token位置的向量\n",
    "        # y = torch.cosine_similarity(sequence_output[:,-1,:].unsqueeze(1).repeat((1,seq_len,1)), test_embeddings, dim=-1).squeeze()\n",
    "        y = torch.sigmoid(torch.sum(sequence_output[:,-1,:].unsqueeze(1) * test_embeddings, dim=-1)).squeeze()\n",
    "        return y\n",
    "model = SASRec(num_items=num_items, embedding_dim=dim, seq_len=train_seq_len, num_attention_heads=num_attention_heads, num_hidden_layers=num_hidden_layers, hidden_dropout_prob=0., attention_probs_dropout_prob=0.).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=0.002)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T07:20:57.949282600Z",
     "start_time": "2023-09-04T07:20:20.913612100Z"
    }
   },
   "id": "aa509bb36cfb8143"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-04 16:53:24] epoch=[1/10], train_ce_loss: 0.7475, train_ndcg: 0.6297, validate_ce_loss: 0.7493, validate_ndcg: 0.6096\n",
      "[2023-09-04 16:53:28] epoch=[2/10], train_ce_loss: 0.7351, train_ndcg: 0.7317, validate_ce_loss: 0.7513, validate_ndcg: 0.6235\n",
      "[2023-09-04 16:53:32] epoch=[3/10], train_ce_loss: 0.7139, train_ndcg: 0.7865, validate_ce_loss: 0.7568, validate_ndcg: 0.6260\n",
      "[2023-09-04 16:53:36] epoch=[4/10], train_ce_loss: 0.6921, train_ndcg: 0.8263, validate_ce_loss: 0.7620, validate_ndcg: 0.6285\n",
      "[2023-09-04 16:53:40] epoch=[5/10], train_ce_loss: 0.6768, train_ndcg: 0.8543, validate_ce_loss: 0.7638, validate_ndcg: 0.6294\n",
      "[2023-09-04 16:53:44] epoch=[6/10], train_ce_loss: 0.6679, train_ndcg: 0.8702, validate_ce_loss: 0.7658, validate_ndcg: 0.6283\n",
      "[2023-09-04 16:53:49] epoch=[7/10], train_ce_loss: 0.6621, train_ndcg: 0.8772, validate_ce_loss: 0.7679, validate_ndcg: 0.6306\n",
      "[2023-09-04 16:53:56] epoch=[8/10], train_ce_loss: 0.6582, train_ndcg: 0.8818, validate_ce_loss: 0.7689, validate_ndcg: 0.6303\n",
      "[2023-09-04 16:54:01] epoch=[9/10], train_ce_loss: 0.6553, train_ndcg: 0.8842, validate_ce_loss: 0.7694, validate_ndcg: 0.6308\n",
      "[2023-09-04 16:54:07] epoch=[10/10], train_ce_loss: 0.6530, train_ndcg: 0.8852, validate_ce_loss: 0.7690, validate_ndcg: 0.6299\n"
     ]
    }
   ],
   "source": [
    "# BST：基于transformer建模行为序列（模型本身也没什么创新）\n",
    "# Behavior Sequence Transformer for E-commerce Recommendation in Alibaba\n",
    "# 用户内容特征+上下文特征（这里数据集没有）+对行为序列（item embedding + pos embedding）进行建模\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=100\n",
    "\n",
    "user_feature_vals = {}\n",
    "for i in range(user_num_features):\n",
    "    user_feature_vals[i] = sorted(list(set([val[i] for val in user_info.values()])))\n",
    "    for user, info in user_info.items():\n",
    "        user_info[user][i] = user_feature_vals[i].index(info[i])\n",
    "\n",
    "user_profile_data = np.array([user_info[u] for u in data[:,0]]) # [data_len, ufeature]\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(data[:,1: 1+ train_seq_len] + 1).long(),\n",
    "                                                torch.from_numpy(data[:,1+ train_seq_len:-(pos_num+neg_sample_num)]+1).long()\n",
    "                                                ), batch_size=batch_size, shuffle=True, pin_memory=True) # mask = 0\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(user_profile_data).long(), \n",
    "                                                torch.from_numpy(data[:,1: 1+ train_seq_len] + 1).long(),\n",
    "                                                torch.from_numpy(data[:,-(pos_num+neg_sample_num):] + 1).long()\n",
    "                                               ), batch_size=batch_size, shuffle=False, pin_memory=True) # mask = 0\n",
    "num_items += 1\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(FFN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        output = self.linear_2(self.relu(self.linear_1(x)))\n",
    "        return output\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        return [para for para in self.linear_1.parameters()] + [para for para in self.linear_2.parameters()] + [para for para in self.relu.parameters()]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, att_dim, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        assert att_dim % self.n_heads == 0\n",
    "        self.att_size = int(att_dim / n_heads)\n",
    "        # Query, Key, Value\n",
    "        self._query = nn.Linear(att_dim, att_dim, bias=False)\n",
    "        self._key = nn.Linear(att_dim, att_dim, bias=False)\n",
    "        self._value = nn.Linear(att_dim, att_dim, bias=False)\n",
    "        # Attention Block\n",
    "        self.dense = nn.Linear(att_dim, att_dim, bias=False)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        scale_factor = torch.sqrt(torch.FloatTensor([self.n_heads])).item()\n",
    "        batch_size = q.size(0)\n",
    "        # To Multiple Attention Heads\n",
    "        _query = self._query(q).view(batch_size, -1, self.n_heads, self.att_size).transpose(1, 2)\n",
    "        _key = self._key(k).view(batch_size, -1, self.n_heads, self.att_size).transpose(1, 2)\n",
    "        _value = self._value(v).view(batch_size, -1, self.n_heads, self.att_size).transpose(1, 2)\n",
    "        # Scaled dot-product Attention score\n",
    "        score = torch.matmul(_query, _key.transpose(-2, -1)) / scale_factor\n",
    "        # Mask applied.\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "        # Softmax on Score\n",
    "        score = self.activation(score)\n",
    "        z = torch.matmul(self.dropout(score), _value)\n",
    "        # To fully-connected layer\n",
    "        z = z.transpose(1, 2).reshape(batch_size, -1, self.att_size * self.n_heads)\n",
    "        return self.dense(z)\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mh_attention = MultiHeadAttention(input_size, n_heads)\n",
    "        self.lnorm_1 = nn.LayerNorm(input_size)\n",
    "        self.ff = FFN(input_size, hidden_size)\n",
    "        self.lnorm_2 = nn.LayerNorm(input_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x, mask=None):\n",
    "        attention_out = self.mh_attention(x, x, x, mask)\n",
    "        attention_out = self.lnorm_1(self.dropout(attention_out) + x)\n",
    "        ff_attention = self.ff(attention_out)\n",
    "        return self.lnorm_2(self.dropout(ff_attention) + attention_out)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers, n_heads):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.stack = nn.ModuleList()\n",
    "        for layer in range(n_layers):\n",
    "            self.stack.append(EncoderLayer(input_size, hidden_size, n_heads))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x, mask=None):\n",
    "        for cell in self.stack:\n",
    "            x = cell(self.dropout(x), mask)\n",
    "        return x\n",
    "class BSTransformer(nn.Module):\n",
    "    def __init__(self, max_seq_len: int, num_encoder_layer: int, num_heads: int, user_profile_feature: [tuple], profile_feature_embedding_dim: int, hidden_dim: int, dnn_layer_dims: list[int]):\n",
    "        super(BSTransformer, self).__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        # 内容特征\n",
    "        self.user_profile_feature, self.profile_feature_embedding_dim = user_profile_feature, profile_feature_embedding_dim\n",
    "        self.user_profile_embed = nn.ModuleDict({'user_embed_' + str(i): nn.Embedding(num_embeddings=valcount, embedding_dim=profile_feature_embedding_dim) for i, valcount in user_profile_feature})\n",
    "        self.item_embeddings = nn.Embedding(num_items, hidden_dim, padding_idx=-1)\n",
    "        self.pos_embedding = self.pos_embedding_sinusoidal(max_seq_len, hidden_dim)\n",
    "        self.user_profile_all_embed_dim = profile_feature_embedding_dim * len(user_profile_feature)\n",
    "        self.dnn_layer_dims, self.hidden_dim = dnn_layer_dims, hidden_dim\n",
    "        self.encoder = Encoder(hidden_dim, hidden_dim, num_encoder_layer, num_heads)\n",
    "        # final dnn\n",
    "        self.all_embedding_dim = len(user_profile_feature) * profile_feature_embedding_dim + hidden_dim * 2\n",
    "        self.final_dnn_network = nn.Sequential(nn.Linear(self.all_embedding_dim, dnn_layer_dims[0]), nn.ReLU())\n",
    "        if len(dnn_layer_dims) > 1:\n",
    "            for i, layer_dim in enumerate(dnn_layer_dims[1:]):\n",
    "                self.final_dnn_network.append(nn.Linear(dnn_layer_dims[i], layer_dim))\n",
    "                self.final_dnn_network.append(nn.ReLU())\n",
    "        self.final_dnn_network.append(nn.Linear(dnn_layer_dims[-1], 1))\n",
    "        self.final_dnn_network.append(nn.Sigmoid())\n",
    "    def forward(self, user_profiles, item_history_list, item_future_list):\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        # user profile: [batch, feature * embed_dim]\n",
    "        user_profile_embeddings = torch.cat([self.user_profile_embed['user_embed_' + str(i)](user_profiles[:,i].long()) for i in range(user_profiles.shape[-1])], axis=-1)\n",
    "        user_profile_embeddings = user_profile_embeddings.reshape((batch_len, len(self.user_profile_feature) * self.profile_feature_embedding_dim)) # [batch, feature, embed_dim]\n",
    "        # item_history_list_profile: torch.Tensor([batch, seq_len, feature * embed_dim])\n",
    "        seq_len = item_history_list.shape[1]\n",
    "        enc_mask = self.get_mask(item_history_list)\n",
    "        item_embed = self.item_embeddings(item_history_list.long())\n",
    "        bst_encoding = torch.mean(self.encoder(item_embed + self.pos_embedding, mask=enc_mask), dim=1)\n",
    "        # \n",
    "        seq_len_ = item_future_list.shape[1]\n",
    "        bst_encoding = bst_encoding.unsqueeze(1).repeat((1,seq_len_,1))\n",
    "        user_profile_embeddings = user_profile_embeddings.unsqueeze(1).repeat((1,seq_len_,1))\n",
    "        test_item_embed = self.item_embeddings(item_future_list.long())\n",
    "        output = self.final_dnn_network(torch.cat([bst_encoding, user_profile_embeddings, test_item_embed], dim=-1)).squeeze()\n",
    "        return output\n",
    "    def get_mask(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        mask = (x != 0).unsqueeze(1).byte()\n",
    "        triu = (np.triu(np.ones([1, seq_len, seq_len]), k=1) == 0).astype('uint8')\n",
    "        return mask * triu\n",
    "    @staticmethod\n",
    "    def pos_embedding_sinusoidal(max_seq_len, embedding_dim):\n",
    "        half_dim = embedding_dim // 2\n",
    "        emb = torch.log(torch.tensor(10000)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)\n",
    "        emb = torch.arange(max_seq_len, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.stack((torch.sin(emb), torch.cos(emb)), dim=0).view(\n",
    "            max_seq_len, -1).t().contiguous().view(max_seq_len, -1)\n",
    "        if embedding_dim % 2 == 1:\n",
    "            emb = torch.cat([emb, torch.zeros(max_seq_len, 1)], dim=1)\n",
    "        return emb.to(device)\n",
    "model = BSTransformer(max_seq_len=train_seq_len, num_encoder_layer = 1, num_heads = 4, user_profile_feature = [(i,len(list_)) for i, list_ in user_feature_vals.items()], profile_feature_embedding_dim = dim, hidden_dim = dim, dnn_layer_dims = [16]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        user_profiles, item_history_list, item_future_list = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list = item_history_list.to(device)\n",
    "        item_future_list = item_future_list.to(device)\n",
    "        output = model(user_profiles, item_history_list, item_future_list)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        user_profiles, item_history_list, item_future_list = inputs\n",
    "        batch_len = user_profiles.shape[0]\n",
    "        user_profiles = user_profiles.to(device)\n",
    "        item_history_list = item_history_list.to(device)\n",
    "        item_future_list = item_future_list.to(device)\n",
    "        output = model(user_profiles, item_history_list, item_future_list)\n",
    "        labels = label.unsqueeze(0).repeat([batch_len,1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([batch_len, loss.item(), NDCG(output.cpu().detach().numpy(), labels.cpu().detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T08:54:07.661263700Z",
     "start_time": "2023-09-04T08:53:15.964395500Z"
    }
   },
   "id": "a9bcf051202c4794"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7140178e5226e122"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
