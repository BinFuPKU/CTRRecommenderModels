{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 序列推荐模型\n",
    "# GRU4Rec、DIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446 1548\n",
      "(446, 81)\n",
      "[[ 397  303  260  306  312  744  257  285  338  270  682  862  328 1543\n",
      "   344  881  326  298  867  265  673 1491  301  337  353  261  300 1260\n",
      "  1238  302  325  334  331  351  347 1090  683  901  897  272  345   49\n",
      "   585  309  521  126  386 1282 1038  539  288  417  418  931 1444  804\n",
      "   164  933  941 1326  686 1001  316  324 1128  900 1091 1349  710  716\n",
      "   470 1499  225   98 1508  357  365  757  887  248  633]\n",
      " [ 344  773  365  397  445   48  374   62  431  981  231  780  384  109\n",
      "    39  775 1021  929 1022  393   93  399   89  386  569  715   66 1059\n",
      "   748  414  459  418  139  832  495  831 1413  413  398  396   77  784\n",
      "   717  786   50  142  768  259 1159  394   11  917  793 1306 1307  810\n",
      "   302  944 1328  564   53  293  141  212  778  645  825  839  328  332\n",
      "  1234 1363  342 1247  485  107 1134 1137  369 1277  254]]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集2成序列数据集，评分[0,1,2]为负反馈，评分[3,4,5]为正反馈，只保留正样本，构造简单序列推荐数据集\n",
    "# 数据集：ml-100k\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(100)\n",
    "\n",
    "# 加载数据: >=3分为正，用户评分次数不低于50，只保留最后50个，拆分为40: 5 + 15负例 (随机采样): 5 + 15负例 (随机采样)\n",
    "ratings = np.array([[int(x) for x in line.strip().split('\\t')[:4]] for line in open('./data/ml-100k/ua.base','r').read().strip().split('\\n')], dtype=np.int32)\n",
    "ratings_pd = pd.DataFrame({feature_name: list(feature_data) for feature_name, feature_data in zip(['user_id','item_id','rating','timestamp'], ratings.T)})\n",
    "pos_ratings_pd = ratings_pd[ratings_pd['rating']>2.9][['user_id','item_id','timestamp']].dropna().sort_values('timestamp') # 已经排序了\n",
    "pos_ratings_pd = pos_ratings_pd.groupby('user_id').filter(lambda x: x['user_id'].count()>=50)\n",
    "userid2id = {user_id: i for i, user_id in enumerate(sorted(list(set(pos_ratings_pd['user_id'].tolist()))))}\n",
    "itemid2id = {item_id: i for i, item_id in enumerate(sorted(list(set(pos_ratings_pd['item_id'].tolist()))))}\n",
    "print(len(userid2id), len(itemid2id))\n",
    "del ratings, ratings_pd\n",
    "\n",
    "# new id\n",
    "user_train_validate_test = {}\n",
    "for user,item,t in pos_ratings_pd.values:\n",
    "    u, i = userid2id[user], itemid2id[item]\n",
    "    if u not in user_train_validate_test:\n",
    "        user_train_validate_test[u] = [i]\n",
    "    else:\n",
    "        user_train_validate_test[u].append(i)\n",
    "    user_train_validate_test[u] = user_train_validate_test[u][-50:]\n",
    "train_seq_len = 40\n",
    "pos_num = 5\n",
    "neg_sample_num = 15\n",
    "def sample(low, high, notinset, num):\n",
    "    nums = set([])\n",
    "    n = num\n",
    "    while n>0:\n",
    "        id = random.randint(low, high)\n",
    "        if id not in notinset and id not in nums:\n",
    "            nums.add(id)\n",
    "            n -= 1\n",
    "    return list(nums)\n",
    "data = np.zeros((len(user_train_validate_test), 81), dtype=np.int32)\n",
    "i = 0\n",
    "for user, train_validate_test in user_train_validate_test.items():\n",
    "    train, validate, test = train_validate_test[:train_seq_len], train_validate_test[-pos_num*2:-pos_num], train_validate_test[-pos_num:]\n",
    "    data[i, 0] = user\n",
    "    data[i,1:train_seq_len+1] = np.array(train)\n",
    "    samples = sample(0, len(itemid2id)-1, set(train_validate_test), neg_sample_num * 2)\n",
    "    data[i,1+train_seq_len : 1+train_seq_len+pos_num+neg_sample_num] = np.array(validate + samples[:neg_sample_num])\n",
    "    data[i,1+train_seq_len+pos_num+neg_sample_num : ] = np.array(test + samples[neg_sample_num:])\n",
    "    i += 1\n",
    "del user_train_validate_test\n",
    "print(data.shape)\n",
    "print(data[:2,:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-01T07:32:48.050842Z",
     "start_time": "2023-09-01T07:32:45.311131500Z"
    }
   },
   "id": "92dba20d208aba82"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-01 16:22:16] epoch=[1/10], train_ce_loss: 0.7405, train_ndcg: 0.6901, validate_ce_loss: 0.7556, validate_ndcg: 0.6248\n",
      "[2023-09-01 16:22:20] epoch=[2/10], train_ce_loss: 0.6774, train_ndcg: 0.8633, validate_ce_loss: 0.7632, validate_ndcg: 0.6208\n",
      "[2023-09-01 16:22:23] epoch=[3/10], train_ce_loss: 0.6616, train_ndcg: 0.8945, validate_ce_loss: 0.7653, validate_ndcg: 0.6203\n",
      "[2023-09-01 16:22:27] epoch=[4/10], train_ce_loss: 0.6592, train_ndcg: 0.9063, validate_ce_loss: 0.7659, validate_ndcg: 0.6252\n",
      "[2023-09-01 16:22:30] epoch=[5/10], train_ce_loss: 0.6581, train_ndcg: 0.9107, validate_ce_loss: 0.7662, validate_ndcg: 0.6275\n",
      "[2023-09-01 16:22:34] epoch=[6/10], train_ce_loss: 0.6568, train_ndcg: 0.9145, validate_ce_loss: 0.7664, validate_ndcg: 0.6273\n",
      "[2023-09-01 16:22:38] epoch=[7/10], train_ce_loss: 0.6549, train_ndcg: 0.9156, validate_ce_loss: 0.7665, validate_ndcg: 0.6279\n",
      "[2023-09-01 16:22:41] epoch=[8/10], train_ce_loss: 0.6524, train_ndcg: 0.9182, validate_ce_loss: 0.7673, validate_ndcg: 0.6283\n",
      "[2023-09-01 16:22:45] epoch=[9/10], train_ce_loss: 0.6491, train_ndcg: 0.9213, validate_ce_loss: 0.7681, validate_ndcg: 0.6258\n",
      "[2023-09-01 16:22:48] epoch=[10/10], train_ce_loss: 0.6453, train_ndcg: 0.9226, validate_ce_loss: 0.7690, validate_ndcg: 0.6240\n"
     ]
    }
   ],
   "source": [
    "# GRU4Rec: \n",
    "# user_embedding = GRU(item_embedding_seq)\n",
    "# y = user_embedding * item_embedding.T\n",
    "# 数据集：ml-100k\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, CrossEntropyLoss, Sequential, Linear, Sigmoid\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "dim=100\n",
    "\n",
    "train_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len]).long(), torch.from_numpy(data[:,1+ train_seq_len:-(pos_num+neg_sample_num)]).long()), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(data[:,1: 1+ train_seq_len + pos_num]).long(), torch.from_numpy(data[:,-(pos_num+neg_sample_num) : ]).long()), batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, gru_num_layers=1):\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim, self.gru_num_layers = embedding_dim, gru_num_layers\n",
    "        self.item_embeddings = nn.Embedding(num_items, self.embedding_dim, padding_idx=-1)\n",
    "        torch.nn.init.kaiming_normal_(self.item_embeddings.weight.data)\n",
    "        self.gru = nn.GRU(input_size=self.embedding_dim, hidden_size=self.embedding_dim, num_layers=self.gru_num_layers, batch_first=True)\n",
    "    # [batch, seq_len], [batch, label_len]\n",
    "    def forward(self, item_seqs: torch.Tensor, test: torch.Tensor):\n",
    "        batch_len = item_seqs.shape[0]\n",
    "        # [batch, seq_len, dim]\n",
    "        item_seqs_embeddings = self.item_embeddings(item_seqs)\n",
    "        # [batch, label_len, dim]\n",
    "        test_embeddings = self.item_embeddings(test)\n",
    "        # gru输出最后的隐层输出当为user embedding\n",
    "        _, user_emb = self.gru(item_seqs_embeddings)\n",
    "        # [batch, dim * gru_num_layers]\n",
    "        user_emb = user_emb.reshape((batch_len, self.gru_num_layers * self.embedding_dim))\n",
    "        # predict\n",
    "        scores = torch.sigmoid(torch.bmm(test_embeddings.repeat([1,1,self.gru_num_layers]), user_emb.unsqueeze(-1)).squeeze())\n",
    "        return scores\n",
    "model = GRU4Rec(num_items = len(itemid2id), embedding_dim = dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n",
    "criterion = CrossEntropyLoss(reduction='sum').to(device)\n",
    "label = torch.FloatTensor([1 for i in range(pos_num)] + [0 for i in range(neg_sample_num)]).to(device)\n",
    "\n",
    "def DCG(batch_labels):\n",
    "    dcgsum = np.zeros((batch_labels.shape[0]))\n",
    "    for i in range(batch_labels.shape[-1]):\n",
    "        dcg = (2 ** batch_labels[:,i] - 1) / np.math.log(i + 2, 2)\n",
    "        dcgsum += dcg\n",
    "    return dcgsum\n",
    "def NDCG(output, labels):\n",
    "    # ideal_dcg\n",
    "    ideal_dcg = DCG(labels)\n",
    "    # this\n",
    "    dcg = DCG((np.argsort( - output, axis=-1)<pos_num).astype(np.float32))\n",
    "    return np.sum(dcg/ideal_dcg)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train:\n",
    "    epoch_train_losses = []\n",
    "    model.train()\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    # validate:\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        item_seqs = inputs[0].to(device)\n",
    "        test = inputs[1].to(device)\n",
    "        output = model(item_seqs, test)\n",
    "        labels = label.unsqueeze(0).repeat([item_seqs.shape[0],1])\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_test_losses.append([item_seqs.shape[0], loss.item(), NDCG(output.detach().numpy(), labels.detach().numpy())])\n",
    "    train_loss = sum([x[1] for x in epoch_train_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_train_losses])\n",
    "    test_loss  = sum([x[1] for x in epoch_test_losses])/sum([x[0] * (pos_num + neg_sample_num) for x in epoch_test_losses])\n",
    "    train_ndcg = sum([x[2] for x in epoch_train_losses])/sum([x[0] for x in epoch_train_losses])\n",
    "    test_ndcg  = sum([x[2] for x in epoch_test_losses])/sum([x[0] for x in epoch_test_losses])\n",
    "    # print\n",
    "    print('['+datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+']', 'epoch=[{}/{}], train_ce_loss: {:.4f}, train_ndcg: {:.4f}, validate_ce_loss: {:.4f}, validate_ndcg: {:.4f}'.format(epoch+1, num_epochs,  train_loss, train_ndcg, test_loss, test_ndcg))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-01T08:22:48.694168200Z",
     "start_time": "2023-09-01T08:22:13.104247100Z"
    }
   },
   "id": "133c7cc9f9ed46e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DIEN\n",
    "# Deep Interest Evolution Network for Click-Through Rate Prediction, 2018\n",
    "# 数据集：ml-100k\n",
    "\n",
    "\n",
    "class InterestExtractor(nn.Module):\n",
    "    def __init__(self, input_size, use_neg=False, dnn_hidden_units=[100, 50, 1], init_std=0.001):\n",
    "        super(InterestExtractor, self).__init__()\n",
    "        self.use_neg = use_neg\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        if self.use_neg:\n",
    "            self.auxiliary_net = DNN(input_size * 2, dnn_hidden_units, 'sigmoid', init_std=init_std)\n",
    "        for name, tensor in self.gru.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "    def forward(self, keys, keys_length, neg_keys=None):\n",
    "        \"\"\"\n",
    "        keys:        [btz, seq_len, hdsz]\n",
    "        keys_length: [btz, 1]\n",
    "        neg_keys:    [btz, seq_len, hdsz]   \n",
    "        \"\"\"\n",
    "        btz, seq_len, hdsz = keys.shape\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return torch.zeros(btz, hdsz, device=keys.device)\n",
    "\n",
    "        # 过RNN\n",
    "        masked_keys = torch.masked_select(keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)  # 去除全为0序列的样本\n",
    "        packed_keys = pack_padded_sequence(masked_keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_interests, _ = self.gru(packed_keys)\n",
    "        interests, _ = pad_packed_sequence(packed_interests, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "\n",
    "        # 计算auxiliary_loss\n",
    "        if self.use_neg and neg_keys is not None:\n",
    "            masked_neg_keys = torch.masked_select(neg_keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "            aux_loss = self._cal_auxiliary_loss(interests[:, :-1, :], masked_keys[:, 1:, :], \n",
    "                                                masked_neg_keys[:, 1:, :], keys_length - 1)\n",
    "        return interests, aux_loss\n",
    "\n",
    "    def _cal_auxiliary_loss(self, states, click_seq, noclick_seq, keys_length):\n",
    "        \"\"\"\n",
    "        states:        [btz, seq_len, hdsz]\n",
    "        click_seq:     [btz, seq_len, hdsz]   \n",
    "        noclick_seq:   [btz, seq_len, hdsz]\n",
    "        keys_length:   [btz, 1]\n",
    "        \"\"\"\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return torch.zeros((1,), device=states.device)\n",
    "        \n",
    "        # 去除全为0序列的样本\n",
    "        btz, seq_len, hdsz = states.shape\n",
    "        states = torch.masked_select(states, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "        click_seq = torch.masked_select(click_seq, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "        noclick_seq = torch.masked_select(noclick_seq, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "\n",
    "        # 仅对非mask部分计算loss\n",
    "        mask = torch.arange(seq_len, device=states.device) < keys_length[:, None]\n",
    "        click_input = torch.cat([states, click_seq], dim=-1)  # [btz, seq_len, hdsz*2]\n",
    "        noclick_input = torch.cat([states, noclick_seq], dim=-1)  # [btz, seq_len, hdsz*2]\n",
    "        click_p = self.auxiliary_net(click_input.view(-1, hdsz*2)).view(btz, seq_len)[mask].view(-1, 1)\n",
    "        noclick_p = self.auxiliary_net(noclick_input.view(-1, hdsz*2)).view(btz, seq_len)[mask].view(-1, 1)\n",
    "        click_target = torch.ones_like(click_p)\n",
    "        noclick_target = torch.zeros_like(click_p)\n",
    "\n",
    "        loss = F.binary_cross_entropy(torch.cat([click_p, noclick_p], dim=0), torch.cat([click_target, noclick_target], dim=0))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AGRUCell(nn.Module):\n",
    "    \"\"\" Attention based GRU (AGRU)\n",
    "\n",
    "        Reference:\n",
    "        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(AGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # (W_ir|W_iz|W_ih)\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n",
    "        self.register_parameter('weight_ih', self.weight_ih)\n",
    "        # (W_hr|W_hz|W_hh)\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n",
    "        self.register_parameter('weight_hh', self.weight_hh)\n",
    "        if bias:\n",
    "            # (b_ir|b_iz|b_ih)\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_ih)\n",
    "            # (b_hr|b_hz|b_hh)\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_hh', self.bias_hh)\n",
    "            for tensor in [self.bias_ih, self.bias_hh]:\n",
    "                nn.init.zeros_(tensor, )\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "    def forward(self, inputs, hx, att_score):\n",
    "        gi = F.linear(inputs, self.weight_ih, self.bias_ih)\n",
    "        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n",
    "        i_r, _, i_n = gi.chunk(3, 1)\n",
    "        h_r, _, h_n = gh.chunk(3, 1)\n",
    "\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        # update_gate = torch.sigmoid(i_z + h_z)\n",
    "        new_state = torch.tanh(i_n + reset_gate * h_n)\n",
    "\n",
    "        att_score = att_score.view(-1, 1)\n",
    "        hy = (1. - att_score) * hx + att_score * new_state\n",
    "        return hy\n",
    "\n",
    "\n",
    "class AUGRUCell(nn.Module):\n",
    "    \"\"\" Effect of GRU with attentional update gate (AUGRU)\n",
    "\n",
    "        Reference:\n",
    "        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(AUGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # (W_ir|W_iz|W_ih)\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n",
    "        self.register_parameter('weight_ih', self.weight_ih)\n",
    "        # (W_hr|W_hz|W_hh)\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n",
    "        self.register_parameter('weight_hh', self.weight_hh)\n",
    "        if bias:\n",
    "            # (b_ir|b_iz|b_ih)\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_ih)\n",
    "            # (b_hr|b_hz|b_hh)\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_hh)\n",
    "            for tensor in [self.bias_ih, self.bias_hh]:\n",
    "                nn.init.zeros_(tensor, )\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "    def forward(self, inputs, hx, att_score):\n",
    "        gi = F.linear(inputs, self.weight_ih, self.bias_ih)\n",
    "        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n",
    "        i_r, i_z, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_z, h_n = gh.chunk(3, 1)\n",
    "\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        update_gate = torch.sigmoid(i_z + h_z)\n",
    "        new_state = torch.tanh(i_n + reset_gate * h_n)\n",
    "\n",
    "        att_score = att_score.view(-1, 1)\n",
    "        update_gate = att_score * update_gate\n",
    "        hy = (1. - update_gate) * hx + update_gate * new_state\n",
    "        return hy\n",
    "\n",
    "\n",
    "class DynamicGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, gru_type='AGRU'):\n",
    "        super(DynamicGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if gru_type == 'AGRU':\n",
    "            self.rnn = AGRUCell(input_size, hidden_size, bias)\n",
    "        elif gru_type == 'AUGRU':\n",
    "            self.rnn = AUGRUCell(input_size, hidden_size, bias)\n",
    "\n",
    "    def forward(self, inputs, att_scores=None, hx=None):\n",
    "        if not isinstance(inputs, PackedSequence) or not isinstance(att_scores, PackedSequence):\n",
    "            raise NotImplementedError(\"DynamicGRU only supports packed input and att_scores\")\n",
    "\n",
    "        inputs, batch_sizes, sorted_indices, unsorted_indices = inputs\n",
    "        att_scores, _, _, _ = att_scores\n",
    "\n",
    "        max_batch_size = int(batch_sizes[0])\n",
    "        if hx is None:\n",
    "            hx = torch.zeros(max_batch_size, self.hidden_size,\n",
    "                             dtype=inputs.dtype, device=inputs.device)\n",
    "\n",
    "        outputs = torch.zeros(inputs.size(0), self.hidden_size,\n",
    "                              dtype=inputs.dtype, device=inputs.device)\n",
    "\n",
    "        begin = 0\n",
    "        for batch in batch_sizes:\n",
    "            new_hx = self.rnn(\n",
    "                inputs[begin:begin + batch],\n",
    "                hx[0:batch],\n",
    "                att_scores[begin:begin + batch])\n",
    "            outputs[begin:begin + batch] = new_hx\n",
    "            hx = new_hx\n",
    "            begin += batch\n",
    "        return PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "\n",
    "\n",
    "class InterestEvolving(nn.Module):\n",
    "    \"\"\"DIEN中的兴趣演化模块\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, gru_type='GRU', use_neg=False, init_std=0.001, \n",
    "                 att_hidden_size=(64, 16), att_activation='sigmoid', att_weight_normalization=False):\n",
    "        super(InterestEvolving, self).__init__()\n",
    "        assert gru_type in {'GRU', 'AIGRU', 'AGRU', 'AUGRU'}, f\"gru_type: {gru_type} is not supported\"\n",
    "        self.gru_type = gru_type\n",
    "\n",
    "        return_score = True\n",
    "        if gru_type == 'GRU':\n",
    "            return_score = False\n",
    "            self.interest_evolution = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        elif gru_type == 'AIGRU':\n",
    "            self.interest_evolution = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        elif gru_type == 'AGRU' or gru_type == 'AUGRU':\n",
    "            self.interest_evolution = DynamicGRU(input_size=input_size, hidden_size=input_size, gru_type=gru_type)\n",
    "\n",
    "        self.attention = AttentionSequencePoolingLayer(embedding_dim=input_size, att_hidden_units=att_hidden_size, att_activation=att_activation,\n",
    "                                                       weight_normalization=att_weight_normalization, return_score=return_score)\n",
    "\n",
    "        for name, tensor in self.interest_evolution.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_last_state(states, keys_length):\n",
    "        # states [B, T, H]\n",
    "        batch_size, max_seq_length, _ = states.size()\n",
    "\n",
    "        mask = (torch.arange(max_seq_length, device=keys_length.device).repeat(\n",
    "            batch_size, 1) == (keys_length.view(-1, 1) - 1))\n",
    "\n",
    "        return states[mask]\n",
    "\n",
    "    def forward(self, query, keys, keys_length, mask=None):\n",
    "        \"\"\"\n",
    "        query:       [btz, 1, hdsz]\n",
    "        keys:        [btz, seq_len ,hdsz]\n",
    "        keys_length: [btz, 1]\n",
    "        \"\"\"\n",
    "        btz, seq_len, hdsz = keys.shape\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        zero_outputs = torch.zeros(btz, hdsz, device=query.device)\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return zero_outputs\n",
    "\n",
    "        query = torch.masked_select(query, smp_mask.view(-1, 1, 1)).view(-1, 1, hdsz)\n",
    "        keys = torch.masked_select(keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)  # 去除全为0序列的样本\n",
    "\n",
    "        if self.gru_type == 'GRU':\n",
    "            packed_keys = pack_padded_sequence(keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_interests, _ = self.interest_evolution(packed_keys)\n",
    "            interests, _ = pad_packed_sequence(packed_interests, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "            outputs = self.attention(query, interests, keys_length.unsqueeze(1))  # [btz1, 1, hdsz]\n",
    "            outputs = outputs.squeeze(1)  # [btz1, hdsz]\n",
    "\n",
    "        elif self.gru_type == 'AIGRU':\n",
    "            att_scores = self.attention(query, keys, keys_length.unsqueeze(1))  # [btz1, 1, seq_len]\n",
    "            interests = keys * att_scores.transpose(1,2)  # [btz1, seq_len, hdsz]\n",
    "            packed_interests = pack_padded_sequence(interests, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, outputs = self.interest_evolution(packed_interests)\n",
    "            outputs = outputs.squeeze(0)  # [btz1, hdsz]\n",
    "\n",
    "        elif self.gru_type == 'AGRU' or self.gru_type == 'AUGRU':\n",
    "            att_scores = self.attention(query, keys, keys_length.unsqueeze(1)).squeeze(1)  # [b, T]\n",
    "            packed_interests = pack_padded_sequence(keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_scores = pack_padded_sequence(att_scores, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            outputs = self.interest_evolution(packed_interests, packed_scores)\n",
    "            outputs, _ = pad_packed_sequence(outputs, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "            # pick last state\n",
    "            outputs = InterestEvolving._get_last_state(outputs, keys_length) # [b, H]\n",
    "            \n",
    "        # [b, H] -> [B, H]\n",
    "        zero_outputs[smp_mask.squeeze(1)] = outputs\n",
    "        return zero_outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2558880992908a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class InterestEvolving(nn.Module):\n",
    "    \"\"\"DIEN中的兴趣演化模块\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, gru_type='GRU', use_neg=False, init_std=0.001, \n",
    "                 att_hidden_size=(64, 16), att_activation='sigmoid', att_weight_normalization=False):\n",
    "        super(InterestEvolving, self).__init__()\n",
    "        assert gru_type in {'GRU', 'AIGRU', 'AGRU', 'AUGRU'}, f\"gru_type: {gru_type} is not supported\"\n",
    "        self.gru_type = gru_type\n",
    "\n",
    "        return_score = True\n",
    "        if gru_type == 'GRU':\n",
    "            return_score = False\n",
    "            self.interest_evolution = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        elif gru_type == 'AIGRU':\n",
    "            self.interest_evolution = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        elif gru_type == 'AGRU' or gru_type == 'AUGRU':\n",
    "            self.interest_evolution = DynamicGRU(input_size=input_size, hidden_size=input_size, gru_type=gru_type)\n",
    "\n",
    "        self.attention = AttentionSequencePoolingLayer(embedding_dim=input_size, att_hidden_units=att_hidden_size, att_activation=att_activation,\n",
    "                                                       weight_normalization=att_weight_normalization, return_score=return_score)\n",
    "\n",
    "        for name, tensor in self.interest_evolution.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_last_state(states, keys_length):\n",
    "        # states [B, T, H]\n",
    "        batch_size, max_seq_length, _ = states.size()\n",
    "\n",
    "        mask = (torch.arange(max_seq_length, device=keys_length.device).repeat(\n",
    "            batch_size, 1) == (keys_length.view(-1, 1) - 1))\n",
    "\n",
    "        return states[mask]\n",
    "\n",
    "    def forward(self, query, keys, keys_length, mask=None):\n",
    "        \"\"\"\n",
    "        query:       [btz, 1, hdsz]\n",
    "        keys:        [btz, seq_len ,hdsz]\n",
    "        keys_length: [btz, 1]\n",
    "        \"\"\"\n",
    "        btz, seq_len, hdsz = keys.shape\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        zero_outputs = torch.zeros(btz, hdsz, device=query.device)\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return zero_outputs\n",
    "\n",
    "        query = torch.masked_select(query, smp_mask.view(-1, 1, 1)).view(-1, 1, hdsz)\n",
    "        keys = torch.masked_select(keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)  # 去除全为0序列的样本\n",
    "\n",
    "        if self.gru_type == 'GRU':\n",
    "            packed_keys = pack_padded_sequence(keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_interests, _ = self.interest_evolution(packed_keys)\n",
    "            interests, _ = pad_packed_sequence(packed_interests, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "            outputs = self.attention(query, interests, keys_length.unsqueeze(1))  # [btz1, 1, hdsz]\n",
    "            outputs = outputs.squeeze(1)  # [btz1, hdsz]\n",
    "\n",
    "        elif self.gru_type == 'AIGRU':\n",
    "            att_scores = self.attention(query, keys, keys_length.unsqueeze(1))  # [btz1, 1, seq_len]\n",
    "            interests = keys * att_scores.transpose(1,2)  # [btz1, seq_len, hdsz]\n",
    "            packed_interests = pack_padded_sequence(interests, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, outputs = self.interest_evolution(packed_interests)\n",
    "            outputs = outputs.squeeze(0)  # [btz1, hdsz]\n",
    "\n",
    "        elif self.gru_type == 'AGRU' or self.gru_type == 'AUGRU':\n",
    "            att_scores = self.attention(query, keys, keys_length.unsqueeze(1)).squeeze(1)  # [b, T]\n",
    "            packed_interests = pack_padded_sequence(keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_scores = pack_padded_sequence(att_scores, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            outputs = self.interest_evolution(packed_interests, packed_scores)\n",
    "            outputs, _ = pad_packed_sequence(outputs, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "            # pick last state\n",
    "            outputs = InterestEvolving._get_last_state(outputs, keys_length) # [b, H]\n",
    "            \n",
    "        # [b, H] -> [B, H]\n",
    "        zero_outputs[smp_mask.squeeze(1)] = outputs\n",
    "        return zero_outputs\n",
    "    \n",
    "class DIN(RecBase):\n",
    "    \"\"\"Deep Interest Network实现\n",
    "    \"\"\"\n",
    "    def __init__(self, dnn_feature_columns, item_history_list, dnn_hidden_units=(256, 128),\n",
    "                 att_hidden_units=(64, 16), att_activation='Dice', att_weight_normalization=False,\n",
    "                 l2_reg_embedding=1e-5, l2_reg_dnn=0, init_std=1e-4,\n",
    "                 dnn_dropout=0, dnn_activation='relu', dnn_use_bn=False, out_dim=1, **kwargs):\n",
    "        super(DIN, self).__init__([], dnn_feature_columns, l2_reg_embedding=l2_reg_embedding, init_std=init_std, out_dim=out_dim, **kwargs)\n",
    "        del self.linear_model  # 删除不必要的网络结构\n",
    "        \n",
    "        self.sparse_feature_columns, self.dense_feature_columns, self.varlen_sparse_feature_columns = split_columns(dnn_feature_columns)\n",
    "        self.item_history_list = item_history_list\n",
    "\n",
    "        # 把varlen_sparse_feature_columns分解成hist、neg_hist和varlen特征\n",
    "        # 其实是DIEN的逻辑（为了避免多次执行），DIN中少了neg模块，DIEN是在deepctr是在forward中会重复执行多次\n",
    "        self.history_feature_names = list(map(lambda x: \"hist_\"+x, item_history_list))\n",
    "        self.neg_history_feature_names = list(map(lambda x: \"neg_\" + x, self.history_feature_names))\n",
    "        self.history_feature_columns = []\n",
    "        self.neg_history_feature_columns = []\n",
    "        self.sparse_varlen_feature_columns = []\n",
    "        for fc in self.varlen_sparse_feature_columns:\n",
    "            feature_name = fc.name\n",
    "            if feature_name in self.history_feature_names:\n",
    "                self.history_feature_columns.append(fc)\n",
    "            elif feature_name in self.neg_history_feature_names:\n",
    "                self.neg_history_feature_columns.append(fc)\n",
    "            else:\n",
    "                self.sparse_varlen_feature_columns.append(fc)\n",
    "\n",
    "        # Attn模块\n",
    "        att_emb_dim = self._compute_interest_dim()\n",
    "        self.attention = AttentionSequencePoolingLayer(att_hidden_units=att_hidden_units, embedding_dim=att_emb_dim, att_activation=att_activation,\n",
    "                                                       return_score=False, supports_masking=False, weight_normalization=att_weight_normalization)\n",
    "\n",
    "        # DNN模块\n",
    "        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units, activation=dnn_activation, \n",
    "                       dropout_rate=dnn_dropout, use_bn=dnn_use_bn, init_std=init_std)\n",
    "        self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False)\n",
    "        self.add_regularization_weight(filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2=l2_reg_dnn)\n",
    "        self.add_regularization_weight(self.dnn_linear.weight, l2=l2_reg_dnn)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 过embedding\n",
    "        emb_lists, query_emb, keys_emb, keys_length, deep_input_emb = self._get_emb(X)\n",
    "\n",
    "        # 获取变长稀疏特征pooling的结果， [[btz, 1, emb_size]\n",
    "        sequence_embed_dict = embedding_lookup(X, self.embedding_dict, self.feature_index, self.sparse_varlen_feature_columns)\n",
    "        sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, X, self.feature_index, self.sparse_varlen_feature_columns)\n",
    "        \n",
    "        # Attn部分\n",
    "        hist = self.attention(query_emb, keys_emb, keys_length)  # [btz, 1, hdsz]\n",
    "\n",
    "        # dnn部分\n",
    "        dnn_input_emb_list = emb_lists[2]\n",
    "        dnn_input_emb_list += sequence_embed_list\n",
    "        deep_input_emb = torch.cat([deep_input_emb, hist], dim=-1)  # [btz, 1, hdsz]\n",
    "        dnn_input = combined_dnn_input([deep_input_emb], emb_lists[-1])  # [btz, hdsz]\n",
    "        dnn_output = self.dnn(dnn_input)\n",
    "        dnn_logit = self.dnn_linear(dnn_output)\n",
    "\n",
    "        # 输出\n",
    "        y_pred = self.out(dnn_logit)\n",
    "\n",
    "        return y_pred\n",
    "        \n",
    "    def _get_emb(self, X):\n",
    "        # 过embedding，这里改造embedding_lookup使得只经过一次embedding, 加快训练速度\n",
    "        # query_emb_list     [[btz, 1, emb_size], ...]\n",
    "        # keys_emb_list      [[btz, seq_len, emb_size], ...]\n",
    "        # dnn_input_emb_list [[btz, 1, emb_size], ...]\n",
    "        return_feat_list = [self.item_history_list, self.history_feature_names, [fc.name for fc in self.sparse_feature_columns]]\n",
    "        emb_lists = embedding_lookup(X, self.embedding_dict, self.feature_index, self.dnn_feature_columns, return_feat_list=return_feat_list)\n",
    "        query_emb_list, keys_emb_list, dnn_input_emb_list = emb_lists\n",
    "        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in self.dense_feature_columns]\n",
    "        emb_lists.append(dense_value_list)\n",
    "\n",
    "        query_emb = torch.cat(query_emb_list, dim=-1)  # [btz, 1, hdsz]\n",
    "        keys_emb = torch.cat(keys_emb_list, dim=-1)  # [btz, 1, hdsz]\n",
    "        keys_length = maxlen_lookup(X, self.feature_index, self.history_feature_names)  # [btz, 1]\n",
    "        deep_input_emb = torch.cat(dnn_input_emb_list, dim=-1)  # [btz, 1, hdsz]\n",
    "        return emb_lists, query_emb, keys_emb, keys_length, deep_input_emb\n",
    "\n",
    "    def _compute_interest_dim(self):\n",
    "        \"\"\"计算兴趣网络特征维度和\n",
    "        \"\"\"\n",
    "        dim_list = [feat.embedding_dim for feat in self.sparse_feature_columns if feat.name in self.item_history_list]\n",
    "        return sum(dim_list)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae55ee82dfec0944"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class DIEN(DIN):\n",
    "    \"\"\"Deep Interest Evolution Network\n",
    "    \"\"\"\n",
    "    def __init__(self, dnn_feature_columns, item_history_list, gru_type=\"GRU\", use_negsampling=False, alpha=1.0, \n",
    "                 dnn_use_bn=False, dnn_hidden_units=(256, 128), dnn_activation='relu', att_hidden_units=(64, 16), att_activation=\"relu\", \n",
    "                 att_weight_normalization=True, l2_reg_embedding=1e-6, l2_reg_dnn=0, dnn_dropout=0, init_std=0.0001, out_dim=1, **kwargs):\n",
    "        super(DIEN, self).__init__(dnn_feature_columns, item_history_list, dnn_hidden_units, att_hidden_units, att_activation, att_weight_normalization, \n",
    "                                   l2_reg_embedding, l2_reg_dnn, init_std, dnn_dropout, dnn_activation, dnn_use_bn, out_dim, **kwargs)\n",
    "        del self.attention\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # 兴趣提取层\n",
    "        input_size = self._compute_interest_dim()\n",
    "        self.interest_extractor = InterestExtractor(input_size=input_size, use_neg=use_negsampling, init_std=init_std)\n",
    "\n",
    "        # 兴趣演变层\n",
    "        self.interest_evolution = InterestEvolving(input_size=input_size, gru_type=gru_type, use_neg=use_negsampling, init_std=init_std,\n",
    "                                                   att_hidden_size=att_hidden_units, att_activation=att_activation, att_weight_normalization=att_weight_normalization)\n",
    "        \n",
    "        # DNN\n",
    "        dnn_input_size = self.compute_input_dim(dnn_feature_columns, [('sparse', 'dense')]) + input_size\n",
    "        self.dnn = DNN(dnn_input_size, dnn_hidden_units, activation=dnn_activation, \n",
    "                       dropout_rate=dnn_dropout, use_bn=dnn_use_bn, init_std=init_std)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 过embedding\n",
    "        emb_lists, query_emb, keys_emb, keys_length, deep_input_emb = self._get_emb(X)\n",
    "        neg_keys_emb_list = embedding_lookup(X, self.embedding_dict, self.feature_index, self.dnn_feature_columns, return_feat_list=self.neg_history_feature_names)\n",
    "        neg_keys_emb = torch.cat(neg_keys_emb_list, dim=-1)  # [btz, 1, hdsz]\n",
    "\n",
    "        # 过兴趣提取层\n",
    "        # input shape: [btz, seq_len, hdsz],  [btz, 1], [btz, seq_len, hdsz]\n",
    "        # masked_interest shape: [btz, seq_len, hdsz]\n",
    "        masked_interest, aux_loss = self.interest_extractor(keys_emb, keys_length, neg_keys_emb)\n",
    "        self.add_auxiliary_loss(aux_loss, self.alpha)\n",
    "\n",
    "        # 过兴趣演变层\n",
    "        hist = self.interest_evolution(query_emb, masked_interest, keys_length)  # [btz, hdsz]\n",
    "\n",
    "        # dnn部分\n",
    "        deep_input_emb = torch.cat([deep_input_emb.squeeze(1), hist], dim=-1)  # [btz, hdsz]\n",
    "        dnn_input = combined_dnn_input([deep_input_emb], emb_lists[-1])  # [btz, hdsz]\n",
    "        dnn_output = self.dnn(dnn_input)\n",
    "        dnn_logit = self.dnn_linear(dnn_output)\n",
    "\n",
    "        # 输出\n",
    "        y_pred = self.out(dnn_logit)\n",
    "\n",
    "        return y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed56678fc0da646"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class SequencePoolingLayer(nn.Module):\n",
    "    \"\"\"seq输入转Pooling，支持多种pooling方式\n",
    "    \"\"\"\n",
    "    def __init__(self, mode='mean', support_masking=False):\n",
    "        super(SequencePoolingLayer, self).__init__()\n",
    "        assert mode in {'sum', 'mean', 'max'}, 'parameter mode should in [sum, mean, max]'\n",
    "        self.mode = mode\n",
    "        self.support_masking = support_masking\n",
    "    \n",
    "    def forward(self, seq_value_len_list):\n",
    "        # seq_value_len_list: [btz, seq_len, hdsz], [btz, seq_len]/[btz,1]\n",
    "        seq_input, seq_len = seq_value_len_list\n",
    "\n",
    "        if self.support_masking:  # 传入的是mask\n",
    "            mask = seq_len.float()\n",
    "            user_behavior_len = torch.sum(mask, dim=-1, keepdim=True)  # [btz, 1]\n",
    "            mask = mask.unsqueeze(2)  # [btz, seq_len, 1]\n",
    "        else:  # 传入的是behavior长度\n",
    "            user_behavior_len = seq_len\n",
    "            mask = torch.arange(0, seq_input.shape[1]) < user_behavior_len.unsqueeze(-1)\n",
    "            mask = torch.transpose(mask, 1, 2)  # [btz, seq_len, 1]\n",
    "        \n",
    "        mask = torch.repeat_interleave(mask, seq_input.shape[-1], dim=2)  # [btz, seq_len, hdsz]\n",
    "        mask = (1 - mask).bool()\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            seq_input = torch.masked_fill(seq_input, mask, 1e-8)\n",
    "            return torch.max(seq_input, dim=1, keepdim=True)  # [btz, 1, hdsz]\n",
    "        elif self.mode == 'sum':\n",
    "            seq_input = torch.masked_fill(seq_input, mask, 0)\n",
    "            return torch.sum(seq_input, dim=1, keepdim=True)  # [btz, 1, hdsz]\n",
    "        elif self.mode == 'mean':\n",
    "            seq_input = torch.masked_fill(seq_input, mask, 0)\n",
    "            seq_sum = torch.sum(seq_input, dim=1, keepdim=True)\n",
    "            return seq_sum / (user_behavior_len.unsqueeze(-1) + 1e-8)\n",
    "\n",
    "class AttentionSequencePoolingLayer(nn.Module):\n",
    "    \"\"\"DIN中使用的序列注意力\n",
    "    \"\"\"\n",
    "    def __init__(self, att_hidden_units=(80, 40), att_activation='sigmoid', weight_normalization=False,\n",
    "                 return_score=False, embedding_dim=4, **kwargs):\n",
    "        super(AttentionSequencePoolingLayer, self).__init__()\n",
    "        self.return_score = return_score\n",
    "        self.weight_normalization = weight_normalization\n",
    "        # 局部注意力单元\n",
    "        self.dnn = DNN(input_dim=4 * embedding_dim, hidden_units=att_hidden_units, activation=att_activation, \n",
    "                       dice_dim=kwargs.get('dice_dim', 3), use_bn=kwargs.get('dice_dim', False), dropout_rate=kwargs.get('dropout_rate', 0))\n",
    "        self.dense = nn.Linear(att_hidden_units[-1], 1)\n",
    "\n",
    "    def forward(self, query, keys, keys_length, mask=None):\n",
    "        \"\"\"\n",
    "        query: 候选item, [btz, 1, emb_size]\n",
    "        keys:  历史点击序列, [btz, seq_len, emb_size]\n",
    "        keys_len: keys的长度, [btz, 1]\n",
    "        mask: [btz, seq_len]\n",
    "        \"\"\"\n",
    "        btz, seq_len, emb_size = keys.shape\n",
    "\n",
    "        # 计算注意力分数\n",
    "        queries = query.expand(-1, seq_len, -1)\n",
    "        attn_input = torch.cat([queries, keys, queries-keys, queries*keys], dim=-1)  # [btz, seq_len, 4*emb_size]\n",
    "        attn_output = self.dnn(attn_input)  # [btz, seq_len, hidden_units[-1]]\n",
    "        attn_score = self.dense(attn_output)  # [btz, seq_len, 1]\n",
    "\n",
    "        # Mask处理\n",
    "        if mask is not None:\n",
    "            keys_mask = mask.unsqueeze(1)  # [btz, 1, seq_len]\n",
    "        else:\n",
    "            keys_mask = torch.arange(seq_len, device=keys.device).repeat(btz, 1)  # [btz, seq_len]\n",
    "            keys_mask = keys_mask < keys_length\n",
    "            keys_mask = keys_mask.unsqueeze(1)  # [btz, 1, seq_len]\n",
    "\n",
    "        attn_score = attn_score.transpose(1, 2)  # [btz, 1, seq_len]\n",
    "        if self.weight_normalization:\n",
    "            # padding置为-inf，这样softmax后就是0\n",
    "            attn_score = torch.masked_fill(attn_score, keys_mask.bool(), -1e-7)\n",
    "            attn_score = F.softmax(attn_score, dim=-1)  # [btz, 1, seq_len]\n",
    "        else:\n",
    "            # padding置为0\n",
    "            attn_score = torch.masked_fill(attn_score, keys_mask.bool(), 0)\n",
    "        \n",
    "        if not self.return_score:\n",
    "            return torch.matmul(attn_score, keys)  # [btz, 1, emb_size]\n",
    "        return attn_score\n",
    "\n",
    "\n",
    "class InterestExtractor(nn.Module):\n",
    "    \"\"\"DIEN中的兴趣提取模块\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, use_neg=False, dnn_hidden_units=[100, 50, 1], init_std=0.001):\n",
    "        super(InterestExtractor, self).__init__()\n",
    "        self.use_neg = use_neg\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=input_size, batch_first=True)\n",
    "        if self.use_neg:\n",
    "            self.auxiliary_net = DNN(input_size * 2, dnn_hidden_units, 'sigmoid', init_std=init_std)\n",
    "        for name, tensor in self.gru.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "    def forward(self, keys, keys_length, neg_keys=None):\n",
    "        \"\"\"\n",
    "        keys:        [btz, seq_len, hdsz]\n",
    "        keys_length: [btz, 1]\n",
    "        neg_keys:    [btz, seq_len, hdsz]   \n",
    "        \"\"\"\n",
    "        btz, seq_len, hdsz = keys.shape\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return torch.zeros(btz, hdsz, device=keys.device)\n",
    "\n",
    "        # 过RNN\n",
    "        masked_keys = torch.masked_select(keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)  # 去除全为0序列的样本\n",
    "        packed_keys = pack_padded_sequence(masked_keys, lengths=keys_length.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_interests, _ = self.gru(packed_keys)\n",
    "        interests, _ = pad_packed_sequence(packed_interests, batch_first=True, padding_value=0.0, total_length=seq_len)\n",
    "\n",
    "        # 计算auxiliary_loss\n",
    "        if self.use_neg and neg_keys is not None:\n",
    "            masked_neg_keys = torch.masked_select(neg_keys, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "            aux_loss = self._cal_auxiliary_loss(interests[:, :-1, :], masked_keys[:, 1:, :], \n",
    "                                                masked_neg_keys[:, 1:, :], keys_length - 1)\n",
    "        return interests, aux_loss\n",
    "\n",
    "    def _cal_auxiliary_loss(self, states, click_seq, noclick_seq, keys_length):\n",
    "        \"\"\"\n",
    "        states:        [btz, seq_len, hdsz]\n",
    "        click_seq:     [btz, seq_len, hdsz]   \n",
    "        noclick_seq:   [btz, seq_len, hdsz]\n",
    "        keys_length:   [btz, 1]\n",
    "        \"\"\"\n",
    "        smp_mask = keys_length > 0\n",
    "        keys_length = keys_length[smp_mask]  # [btz1, 1]\n",
    "\n",
    "        # keys全部为空\n",
    "        if keys_length.shape[0] == 0:\n",
    "            return torch.zeros((1,), device=states.device)\n",
    "        \n",
    "        # 去除全为0序列的样本\n",
    "        btz, seq_len, hdsz = states.shape\n",
    "        states = torch.masked_select(states, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "        click_seq = torch.masked_select(click_seq, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "        noclick_seq = torch.masked_select(noclick_seq, smp_mask.view(-1, 1, 1)).view(-1, seq_len, hdsz)\n",
    "\n",
    "        # 仅对非mask部分计算loss\n",
    "        mask = torch.arange(seq_len, device=states.device) < keys_length[:, None]\n",
    "        click_input = torch.cat([states, click_seq], dim=-1)  # [btz, seq_len, hdsz*2]\n",
    "        noclick_input = torch.cat([states, noclick_seq], dim=-1)  # [btz, seq_len, hdsz*2]\n",
    "        click_p = self.auxiliary_net(click_input.view(-1, hdsz*2)).view(btz, seq_len)[mask].view(-1, 1)\n",
    "        noclick_p = self.auxiliary_net(noclick_input.view(-1, hdsz*2)).view(btz, seq_len)[mask].view(-1, 1)\n",
    "        click_target = torch.ones_like(click_p)\n",
    "        noclick_target = torch.zeros_like(click_p)\n",
    "\n",
    "        loss = F.binary_cross_entropy(torch.cat([click_p, noclick_p], dim=0), torch.cat([click_target, noclick_target], dim=0))\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77eed185b97689fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
